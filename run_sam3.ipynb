{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdd622c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outputs: 7\n",
      "\n",
      "First output keys: dict_keys(['category', 'boxes', 'scores', 'masks'])\n",
      "Category: fish\n",
      "\n",
      "Masks type: <class 'torch.Tensor'>\n",
      "Number of masks: 2\n",
      "\n",
      "First mask type: <class 'torch.Tensor'>\n",
      "First mask shape: torch.Size([1, 480, 640])\n",
      "First mask dtype: torch.bool\n",
      "First mask min/max: False True\n"
     ]
    }
   ],
   "source": [
    "# Debug cell - check mask structure\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Load one test image\n",
    "test_img = Image.open(os.path.join('USIS10K/test', os.listdir('USIS10K/test')[0]))\n",
    "test_state = processor.set_image(test_img)\n",
    "test_outputs = set_multi_text_prompts(processor, test_state, PROMPTS, CATEGORIES)\n",
    "\n",
    "# Check the first output\n",
    "print(\"Number of outputs:\", len(test_outputs))\n",
    "print(\"\\nFirst output keys:\", test_outputs[0].keys())\n",
    "print(\"Category:\", test_outputs[0]['category'])\n",
    "print(\"\\nMasks type:\", type(test_outputs[0]['masks']))\n",
    "print(\"Number of masks:\", len(test_outputs[0]['masks']))\n",
    "\n",
    "if len(test_outputs[0]['masks']) > 0:\n",
    "    first_mask = test_outputs[0]['masks'][0]\n",
    "    print(\"\\nFirst mask type:\", type(first_mask))\n",
    "    print(\"First mask shape:\", first_mask.shape if hasattr(first_mask, 'shape') else 'No shape attribute')\n",
    "    print(\"First mask dtype:\", first_mask.dtype if hasattr(first_mask, 'dtype') else 'No dtype attribute')\n",
    "    print(\"First mask min/max:\", first_mask.min().item() if hasattr(first_mask, 'min') else 'N/A', \n",
    "          first_mask.max().item() if hasattr(first_mask, 'max') else 'N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3713edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\drago\\anaconda3\\envs\\sam3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0850c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from sam3.model_builder import build_sam3_image_model\n",
    "from sam3.model.sam3_image_processor import Sam3Processor\n",
    "# Load the model\n",
    "model = build_sam3_image_model()\n",
    "processor = Sam3Processor(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005c6060",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1596/1596 [55:36<00:00,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1596 predictions to sam3_usis10k_preds_rle.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pycocotools import mask as mask_util\n",
    "\n",
    "# Define categories and their descriptive prompts\n",
    "CATEGORIES = [\"fish\", \"wrecks/ruins\", \"reefs\", \"aquatic plants\", \"human divers\", \"robots\", \"sea-floor\"]\n",
    "PROMPTS = [\n",
    "    \"Underwater vertebrates, e.g., fish, turtles\",\n",
    "    \"Wrecks, ruins, and damaged artifacts underwater\",\n",
    "    \"Underwater invertebrates and coral reefs\",\n",
    "    \"Aquatic plants and flora underwater\",\n",
    "    \"Human divers and their equipment underwater, scuba divers, human body\",\n",
    "    \"Underwater robots, ROVs, and submersibles\",\n",
    "    \"Rocks and bottom substrate on the sea floor\"\n",
    "]\n",
    "\n",
    "def set_multi_text_prompts(processor, state, prompts: list, categories: list):\n",
    "    \"\"\"\n",
    "    Process multiple text prompts in parallel for the same image.\n",
    "    Returns a list of outputs, one per prompt with category labels.\n",
    "    \"\"\"\n",
    "    if \"backbone_out\" not in state:\n",
    "        raise ValueError(\"You must call set_image before set_multi_text_prompts\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Process all prompts at once (batched text encoding)\n",
    "    text_outputs = processor.model.backbone.forward_text(prompts, device=processor.device)\n",
    "    \n",
    "    for idx, (prompt, category) in enumerate(zip(prompts, categories)):\n",
    "        # Create a copy of state for this prompt\n",
    "        prompt_state = {\n",
    "            \"original_height\": state[\"original_height\"],\n",
    "            \"original_width\": state[\"original_width\"],\n",
    "            \"backbone_out\": {**state[\"backbone_out\"]},\n",
    "        }\n",
    "        \n",
    "        # Extract features for this specific prompt\n",
    "        prompt_text_outputs = {\n",
    "            \"language_features\": text_outputs[\"language_features\"][:, idx:idx+1],\n",
    "            \"language_mask\": text_outputs[\"language_mask\"][idx:idx+1],\n",
    "            \"language_embeds\": text_outputs[\"language_embeds\"][:, idx:idx+1],\n",
    "        }\n",
    "        prompt_state[\"backbone_out\"].update(prompt_text_outputs)\n",
    "        \n",
    "        if \"geometric_prompt\" not in prompt_state:\n",
    "            prompt_state[\"geometric_prompt\"] = processor.model._get_dummy_prompt()\n",
    "        \n",
    "        # Run grounding for this prompt\n",
    "        output = processor._forward_grounding(prompt_state)\n",
    "        results.append({\n",
    "            \"category\": category,\n",
    "            \"boxes\": output[\"boxes\"],\n",
    "            \"scores\": output[\"scores\"],\n",
    "            \"masks\": output[\"masks\"],\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def convert_multi_output_to_serializable(multi_outputs):\n",
    "    \"\"\"Convert multi-prompt tensor outputs to JSON-serializable format with RLE encoding\"\"\"\n",
    "    result = {}\n",
    "    for out in multi_outputs:\n",
    "        category = out['category']\n",
    "        \n",
    "        # Convert masks to RLE format\n",
    "        masks_rle = []\n",
    "        for mask in out['masks']:\n",
    "            # Convert tensor to numpy array\n",
    "            # Handle both 2D and 3D masks (squeeze if needed)\n",
    "            mask_np = mask.cpu().numpy()\n",
    "            if mask_np.ndim == 3:\n",
    "                mask_np = mask_np.squeeze(0)  # Remove batch dimension\n",
    "            \n",
    "            # Convert bool to uint8\n",
    "            mask_np = mask_np.astype(np.uint8)\n",
    "            \n",
    "            # Ensure mask is in Fortran order for pycocotools\n",
    "            mask_np = np.asfortranarray(mask_np)\n",
    "            \n",
    "            # Encode to RLE\n",
    "            rle = mask_util.encode(mask_np)\n",
    "            \n",
    "            # Convert bytes to string for JSON serialization\n",
    "            if isinstance(rle['counts'], bytes):\n",
    "                rle['counts'] = rle['counts'].decode('utf-8')\n",
    "            \n",
    "            masks_rle.append(rle)\n",
    "        \n",
    "        result[category] = {\n",
    "            'boxes': out['boxes'].cpu().numpy().tolist(),\n",
    "            'scores': out['scores'].cpu().numpy().tolist(),\n",
    "            'masks': masks_rle,\n",
    "        }\n",
    "    return result\n",
    "\n",
    "preds = []\n",
    "\n",
    "import os\n",
    "imgs = os.listdir('USIS10K/test')\n",
    "for i in tqdm(range(len(imgs))):\n",
    "    # Load image\n",
    "    img = Image.open(os.path.join('USIS10K/test', imgs[i]))\n",
    "    \n",
    "    # Set image\n",
    "    inference_state = processor.set_image(img)\n",
    "\n",
    "    # Run all prompts in parallel\n",
    "    multi_outputs = set_multi_text_prompts(processor, inference_state, PROMPTS, CATEGORIES)\n",
    "    \n",
    "    # Convert tensors to serializable format\n",
    "    serializable_output = convert_multi_output_to_serializable(multi_outputs)\n",
    "    serializable_output['img_path'] = os.path.join('USIS10K/test', imgs[i])\n",
    "    preds.append(serializable_output)\n",
    "\n",
    "    if i % 50 == 0:\n",
    "        with open('sam3_usis10k_preds_rle.json', 'w') as f:\n",
    "            json.dump(preds, f)\n",
    "\n",
    "with open('sam3_usis10k_preds_rle.json', 'w') as f:\n",
    "    json.dump(preds, f)\n",
    "\n",
    "print(f\"Saved {len(preds)} predictions to sam3_usis10k_preds_rle.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4dc05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# preds = []\n",
    "# batch_size = 8  # Adjust based on your GPU memory\n",
    "\n",
    "# for i in tqdm(range(0, len(data), batch_size)):\n",
    "#     batch = data[i:i + batch_size]\n",
    "    \n",
    "#     # Load all images in the batch\n",
    "#     imgs = [Image.open(item['img_path']) for item in batch]\n",
    "    \n",
    "#     # Set image for the first one (if needed by processor)\n",
    "#     inference_state = processor.set_image_batch(imgs)\n",
    "\n",
    "#     outputs = processor.set_text_prompt(state=inference_state, prompt=\"fish or wrecks/ruins or reefs or aquatic plants or human divers or robots or sea-floor\")\n",
    "#     preds.extend(outputs)\n",
    "\n",
    "# with open('sam3_usis10k_preds.json', 'w') as f:\n",
    "#     json.dump(preds, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
