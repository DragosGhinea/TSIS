{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44e7e759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import PIL.Image as Image\n",
    "\n",
    "data = json.loads(open('USIS10K\\\\multi_class_annotations\\\\multi_class_test_annotations.json').read())\n",
    "\n",
    "id_to_img = {}\n",
    "\n",
    "for img in data['images']:\n",
    "    id_to_img[img['id']] = img['file_name']\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from pycocotools import mask as mask_utils\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "PROMPT_TO_CATEGORY = {\n",
    "    \"wrecks/ruins\": 1,\n",
    "    \"fish\": 2,\n",
    "    \"reefs\": 3,\n",
    "    \"aquatic plants\": 4,\n",
    "    \"human divers\": 5,\n",
    "    \"robots\": 6,\n",
    "    \"sea-floor\": 7,\n",
    "}\n",
    "\n",
    "CATEGORY_TO_PROMPT = {v: k for k, v in PROMPT_TO_CATEGORY.items()}\n",
    "\n",
    "\n",
    "def polygon_to_rle(segmentation, img_height, img_width):\n",
    "    # segmentation may be: [x1,y1,...] or [[...]] or list of polygons\n",
    "    if len(segmentation) == 0:\n",
    "        return None\n",
    "\n",
    "    # Normalize to list of polygons\n",
    "    if isinstance(segmentation[0], list):\n",
    "        polys = segmentation\n",
    "    else:\n",
    "        polys = [segmentation]\n",
    "\n",
    "    mask = Image.new(\"L\", (img_width, img_height), 0)\n",
    "    draw = ImageDraw.Draw(mask)\n",
    "\n",
    "    for poly in polys:\n",
    "        coords = np.array(poly).reshape(-1, 2)\n",
    "        draw.polygon(coords.flatten().tolist(), outline=1, fill=1)\n",
    "\n",
    "    mask_np = np.array(mask, dtype=np.uint8)\n",
    "    rle = mask_utils.encode(np.asfortranarray(mask_np))\n",
    "    rle[\"counts\"] = rle[\"counts\"].decode(\"ascii\")\n",
    "\n",
    "    return rle\n",
    "\n",
    "\n",
    "def group_items_to_list(items):\n",
    "    grouped = defaultdict(lambda: defaultdict(lambda: {\"boxes\": [], \"masks_rle\": []}))\n",
    "\n",
    "    for d in items:\n",
    "        img_path = d[\"img_path\"]\n",
    "        img_loaded = Image.open(img_path)\n",
    "\n",
    "        cat = CATEGORY_TO_PROMPT[d[\"category_id\"]]\n",
    "\n",
    "        grouped[img_path][cat][\"boxes\"].append(d[\"bbox\"])\n",
    "        grouped[img_path][cat][\"masks_rle\"].append(\n",
    "            polygon_to_rle(d[\"segmentation\"], img_loaded.height, img_loaded.width)\n",
    "        )\n",
    "\n",
    "    out = []\n",
    "    for img_path, cats in grouped.items():\n",
    "        entry = {\"img_path\": img_path}\n",
    "        entry.update(cats)\n",
    "        out.append(entry)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def load_data(path='USIS10K\\\\multi_class_annotations\\\\multi_class_test_annotations.json'):\n",
    "    data = json.loads(open(path).read())\n",
    "    polished_data = []\n",
    "\n",
    "    for annotation in data['annotations']:\n",
    "        category_id = annotation['category_id']\n",
    "        image_id = annotation['image_id']\n",
    "        bbox = annotation['bbox']\n",
    "        segmentation = annotation['segmentation']\n",
    "        img_path = f\"USIS10K/test/{id_to_img[image_id]}\"\n",
    "\n",
    "        polished_data.append({\n",
    "            'img_path': img_path,\n",
    "            'category_id': category_id,\n",
    "            'bbox': bbox,\n",
    "            'segmentation': segmentation\n",
    "        })\n",
    "\n",
    "    return group_items_to_list(polished_data)\n",
    "\n",
    "def load_usis_preds_data(path='usis_sam_preds_rle.json'):\n",
    "    data = json.loads(open(path).read())\n",
    "    polished_data = []\n",
    "\n",
    "    for annotation in data['predictions']:\n",
    "        category_id = annotation['category_id']\n",
    "        image_id = annotation['image_id']\n",
    "        bbox = annotation['bbox']\n",
    "        segmentation = annotation['segmentation']\n",
    "        img_path = f\"USIS10K/test/{id_to_img[image_id]}\"\n",
    "\n",
    "        polished_data.append({\n",
    "            'img_path': img_path,\n",
    "            'category_id': category_id,\n",
    "            'bbox': bbox,\n",
    "            'segmentation': segmentation\n",
    "        })\n",
    "\n",
    "    return polished_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "079a03a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_data = load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a75be689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing box_2d [180, 480, 680] for image test_01506: list index out of range\n",
      "Error processing box_2d [550, 570, 750] for image test_01506: list index out of range\n"
     ]
    }
   ],
   "source": [
    "def convert_detections(input_data):\n",
    "    \"\"\"\n",
    "    Convert detection data from input format to output format.\n",
    "    \n",
    "    Args:\n",
    "        input_data: List of dictionaries with 'file_name' and 'detections'\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries with 'img_path' and category-based detections\n",
    "    \"\"\"\n",
    "    \n",
    "    # Category mapping\n",
    "    LABEL_TO_CATEGORY = {\n",
    "        \"Fish\": \"fish\",\n",
    "        \"Reefs\": \"reefs\",\n",
    "        \"Aquatic plants\": \"aquatic plants\",\n",
    "        \"Human divers\": \"human divers\",\n",
    "        \"Robots\": \"robots\",\n",
    "        \"Sea-floor\": \"sea-floor\",\n",
    "        \"Wrecks/ruins\": \"wrecks/ruins\"\n",
    "    }\n",
    "    \n",
    "    # All possible categories\n",
    "    ALL_CATEGORIES = [\n",
    "        \"fish\", \"wrecks/ruins\", \"reefs\", \"aquatic plants\", \n",
    "        \"human divers\", \"robots\", \"sea-floor\"\n",
    "    ]\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for item in input_data:\n",
    "        file_name = item['file_name']\n",
    "        detections = item['detections']\n",
    "        \n",
    "        # Initialize output structure\n",
    "        output_item = {\n",
    "            'img_path': f'USIS10K/test/{file_name}.jpg',\n",
    "        }\n",
    "\n",
    "        image = Image.open(output_item['img_path'])\n",
    "        width, height = image.size\n",
    "        \n",
    "        # Initialize all categories with empty lists\n",
    "        for category in ALL_CATEGORIES:\n",
    "            output_item[category] = {\n",
    "                'boxes': [],\n",
    "                'scores': [],\n",
    "                'masks_rle': []\n",
    "            }\n",
    "        \n",
    "        # Group detections by category\n",
    "        for detection in detections:\n",
    "            label = detection['label']\n",
    "            box_2d = detection['box_2d']\n",
    "\n",
    "            try:\n",
    "                abs_y1 = int(box_2d[0]/1000 * height)\n",
    "                abs_x1 = int(box_2d[1]/1000 * width)\n",
    "                abs_y2 = int(box_2d[2]/1000 * height)\n",
    "                abs_x2 = int(box_2d[3]/1000 * width)\n",
    "                new_bbox = [abs_x1, abs_y1, abs_x2, abs_y2]\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing box_2d {box_2d} for image {file_name}: {e}\")\n",
    "                new_bbox = [0, 0, 0, 0]\n",
    "            \n",
    "            # Get the category name (normalize case)\n",
    "            category = LABEL_TO_CATEGORY.get(label)\n",
    "            \n",
    "            if category:\n",
    "                # Add box to the appropriate category\n",
    "                output_item[category]['boxes'].append(new_bbox)\n",
    "                output_item[category]['scores'].append(1.0)  # Default score\n",
    "        \n",
    "        result.append(output_item)\n",
    "    \n",
    "    return result\n",
    "\n",
    "gemini_2_5_flash_converted = convert_detections(json.load(open('gemini_2.5_flash.json')))\n",
    "gemini_2_5_pro_converted = convert_detections(json.load(open('gemini_2.5_pro.json')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "310c13a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1596, 1594, 1596)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gt_data), len(gemini_2_5_flash_converted), len(gemini_2_5_pro_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f90e4871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['img_path', 'fish'])\n",
      "dict_keys(['img_path', 'reefs'])\n",
      "dict_keys(['boxes', 'scores', 'masks_rle'])\n"
     ]
    }
   ],
   "source": [
    "print(gt_data[0].keys())\n",
    "print(gt_data[1].keys())\n",
    "print(gemini_2_5_flash_converted[0]['fish'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "befd18de",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_data = {img['img_path']: img for img in gt_data}\n",
    "gemini_2_5_flash_converted = {img['img_path']: img for img in gemini_2_5_flash_converted}\n",
    "gemini_2_5_pro_converted = {img['img_path']: img for img in gemini_2_5_pro_converted}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "128a4a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'img_path': 'USIS10K/test/test_00001.jpg', 'fish': {'boxes': [[335.0, 243.0, 200.0, 218.0], [117.0, 62.0, 78.0, 180.0]], 'masks_rle': [{'size': [480, 640], 'counts': 'P[m46i>2O2M2N2O1N2N2N2N2M3M3M3N2N2N2O1N2M4L3M3M4L3M3M4L3M3M4L3M3N2M3M4L6J4L3M3N3L5L3M2M3N2N2N1O2N3M2N2N3N1N2N3N1N2O1O2M2O1O1N2O2N1N2O1O1N3N1O1O1O1O1O1N2O001O1O1O1O1O1O1O001O1O1O0000BlFPKT9Q5mFlJT9U5;100O001O100O001O1O100O001O3M2O2M2N1O1O01O01O0001O01O0000010O001O010O001O010O001O010O0010O01O0010O01O010O0010O01O010O0100O1O1O100O1O100O100O2N1O100O2N1O100O2N1O2N2M2O2YLkF_1W9YNRGd1P9WNSGh1P9RNTGn1Q9hMTGW2Y9WMmFV1iN1l;GaD3a;HhD1Z;MmDF\\\\;8hDEX;:mDBS;=QE]OR;b0g1N1N2N3N1O2N1O2O1N3M2O2N3Mlk`1'}, {'size': [480, 640], 'counts': 'imf1k1l<a0B9H8I8J8I6K3M2N3M3M3N2M4M2N3M3N06J4L2N2M2N2M4M2M3M4K4O2M2O1O00102M3NO0M2M3N2N2N1O1000O2N3jL]Di2Q<eMSE5T;LnDG];9e1O010O10O10O10O01000O010000O010O100O00100O1O2N101N2N2N2M`^`6'}]}} {'img_path': 'USIS10K/test/test_00001.jpg', 'fish': {'boxes': [[336, 233, 547, 478], [101, 52, 179, 280], [140, 172, 183, 210]], 'scores': [1.0, 1.0, 1.0], 'masks_rle': []}, 'wrecks/ruins': {'boxes': [], 'scores': [], 'masks_rle': []}, 'reefs': {'boxes': [[0, 0, 320, 230], [320, 0, 640, 192], [160, 96, 448, 384], [0, 312, 128, 475], [96, 384, 160, 436]], 'scores': [1.0, 1.0, 1.0, 1.0, 1.0], 'masks_rle': []}, 'aquatic plants': {'boxes': [], 'scores': [], 'masks_rle': []}, 'human divers': {'boxes': [], 'scores': [], 'masks_rle': []}, 'robots': {'boxes': [], 'scores': [], 'masks_rle': []}, 'sea-floor': {'boxes': [], 'scores': [], 'masks_rle': []}}\n"
     ]
    }
   ],
   "source": [
    "for key in list(gt_data.keys()):\n",
    "    gt_instance = gt_data[key]\n",
    "    gemini_instance = gemini_2_5_flash_converted.get(key)\n",
    "\n",
    "    print(gt_instance, gemini_instance)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0738aa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Calculate IoU between two boxes.\n",
    "    Boxes are in format [x_min, y_min, x_max, y_max]\n",
    "    \"\"\"\n",
    "    x1_min, y1_min, x1_max, y1_max = box1\n",
    "    x2_min, y2_min, x2_max, y2_max = box2\n",
    "    \n",
    "    # Calculate intersection\n",
    "    inter_x_min = max(x1_min, x2_min)\n",
    "    inter_y_min = max(y1_min, y2_min)\n",
    "    inter_x_max = min(x1_max, x2_max)\n",
    "    inter_y_max = min(y1_max, y2_max)\n",
    "    \n",
    "    if inter_x_max <= inter_x_min or inter_y_max <= inter_y_min:\n",
    "        return 0.0\n",
    "    \n",
    "    inter_area = (inter_x_max - inter_x_min) * (inter_y_max - inter_y_min)\n",
    "    \n",
    "    # Calculate union\n",
    "    box1_area = (x1_max - x1_min) * (y1_max - y1_min)\n",
    "    box2_area = (x2_max - x2_min) * (y2_max - y2_min)\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    \n",
    "    return inter_area / union_area if union_area > 0 else 0.0\n",
    "\n",
    "def gt_bbox_to_xyxy(bbox):\n",
    "    \"\"\"\n",
    "    Convert ground truth bbox from [x, y, width, height] to [x_min, y_min, x_max, y_max]\n",
    "    \"\"\"\n",
    "    x, y, w, h = bbox\n",
    "    return [x, y, x + w, y + h]\n",
    "\n",
    "\n",
    "def polygon_to_rle(segmentation, img_height, img_width):\n",
    "    \"\"\"\n",
    "    Convert polygon segmentation to RLE format\n",
    "    \"\"\"\n",
    "    rles = mask_utils.frPyObjects(segmentation, img_height, img_width)\n",
    "    rle = mask_utils.merge(rles)\n",
    "    return rle\n",
    "\n",
    "\n",
    "def calculate_mask_iou(rle1, rle2):\n",
    "    \"\"\"\n",
    "    Calculate IoU between two masks in RLE format\n",
    "    \"\"\"\n",
    "    iou = mask_utils.iou([rle1], [rle2], [0])\n",
    "    return iou[0][0]\n",
    "\n",
    "def evaluate_recall(predictions, gt_data, iou_threshold=0.5, ignore_labels=False):\n",
    "    results = {\n",
    "        'overall': {'total_gt': 0, 'detected': 0, 'recall': 0.0},\n",
    "        'per_category': {}\n",
    "    }\n",
    "\n",
    "    for pred_item, gt_item in zip(predictions, gt_data):\n",
    "        # Iterate through every category in this ground truth item\n",
    "        for gt_category_name, gt_category_data in gt_item.items():\n",
    "            if gt_category_name == \"img_path\":\n",
    "                continue\n",
    "\n",
    "            gt_boxes = gt_category_data[\"boxes\"]\n",
    "\n",
    "            # Ensure category stats exist\n",
    "            if gt_category_name not in results['per_category']:\n",
    "                results['per_category'][gt_category_name] = {\n",
    "                    'total_gt': 0, 'detected': 0, 'recall': 0.0\n",
    "                }\n",
    "\n",
    "            for gt_box in gt_boxes:\n",
    "                gt_xyxy = gt_bbox_to_xyxy(gt_box)\n",
    "\n",
    "                results['overall']['total_gt'] += 1\n",
    "                results['per_category'][gt_category_name]['total_gt'] += 1\n",
    "\n",
    "                detected = False\n",
    "\n",
    "                if ignore_labels:\n",
    "                    # search in ALL predicted categories\n",
    "                    for pred_cat_name, pred_data in pred_item.items():\n",
    "                        if pred_cat_name == \"img_path\":\n",
    "                            continue\n",
    "                        for pred_box in pred_data[\"boxes\"]:\n",
    "                            if calculate_iou(pred_box, gt_xyxy) >= iou_threshold:\n",
    "                                detected = True\n",
    "                                break\n",
    "                        if detected:\n",
    "                            break\n",
    "                else:\n",
    "                    # search only in the SAME predicted category\n",
    "                    if gt_category_name in pred_item:\n",
    "                        for pred_box in pred_item[gt_category_name][\"boxes\"]:\n",
    "                            if calculate_iou(pred_box, gt_xyxy) >= iou_threshold:\n",
    "                                detected = True\n",
    "                                break\n",
    "\n",
    "                if detected:\n",
    "                    results['overall']['detected'] += 1\n",
    "                    results['per_category'][gt_category_name]['detected'] += 1\n",
    "\n",
    "    # Final recall calculations\n",
    "    if results['overall']['total_gt'] > 0:\n",
    "        results['overall']['recall'] = (\n",
    "            results['overall']['detected'] / results['overall']['total_gt']\n",
    "        )\n",
    "\n",
    "    for cat_name, s in results['per_category'].items():\n",
    "        if s['total_gt'] > 0:\n",
    "            s['recall'] = s['detected'] / s['total_gt']\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a84f381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'overall': {'total_gt': 2858, 'detected': 86, 'recall': 0.030090972708187544}, 'per_category': {'fish': {'total_gt': 1565, 'detected': 24, 'recall': 0.015335463258785943}, 'reefs': {'total_gt': 758, 'detected': 56, 'recall': 0.07387862796833773}, 'human divers': {'total_gt': 193, 'detected': 1, 'recall': 0.0051813471502590676}, 'wrecks/ruins': {'total_gt': 153, 'detected': 2, 'recall': 0.013071895424836602}, 'robots': {'total_gt': 47, 'detected': 0, 'recall': 0.0}, 'sea-floor': {'total_gt': 68, 'detected': 3, 'recall': 0.04411764705882353}, 'aquatic plants': {'total_gt': 74, 'detected': 0, 'recall': 0.0}}}\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_recall(gemini_2_5_flash_converted.values(), gt_data.values(), ignore_labels=False)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2510941a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('gemini_2_5_pro_eval_results_label_agnostic.json', 'w') as f:\n",
    "#     json.dump(results, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
