{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a446833f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-30T00:07:55.860685Z",
     "iopub.status.busy": "2025-11-30T00:07:55.860438Z",
     "iopub.status.idle": "2025-11-30T00:07:57.188925Z",
     "shell.execute_reply": "2025-11-30T00:07:57.187925Z"
    },
    "papermill": {
     "duration": 1.335252,
     "end_time": "2025-11-30T00:07:57.190145",
     "exception": false,
     "start_time": "2025-11-30T00:07:55.854893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'USIS10K'...\r\n",
      "remote: Enumerating objects: 880, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (158/158), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (97/97), done.\u001b[K\r\n",
      "remote: Total 880 (delta 122), reused 65 (delta 60), pack-reused 722 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (880/880), 9.21 MiB | 13.79 MiB/s, done.\r\n",
      "Resolving deltas: 100% (319/319), done.\r\n",
      "/kaggle/working/USIS10K\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/LiamLian0727/USIS10K.git\n",
    "%cd USIS10K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "218e2d61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T00:07:57.203974Z",
     "iopub.status.busy": "2025-11-30T00:07:57.203629Z",
     "iopub.status.idle": "2025-11-30T00:10:00.093708Z",
     "shell.execute_reply": "2025-11-30T00:10:00.092664Z"
    },
    "papermill": {
     "duration": 122.900227,
     "end_time": "2025-11-30T00:10:00.095345",
     "exception": false,
     "start_time": "2025-11-30T00:07:57.195118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\r\n",
      "Collecting torch==2.1.2\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torch-2.1.2%2Bcu118-cp311-cp311-linux_x86_64.whl (2325.9 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m551.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting torchvision==0.16.2\r\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.16.2%2Bcu118-cp311-cp311-linux_x86_64.whl (6.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (3.20.0)\r\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (4.15.0)\r\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (1.13.1)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (2025.10.0)\r\n",
      "Collecting triton==2.1.0 (from torch==2.1.2)\r\n",
      "  Downloading https://download.pytorch.org/whl/triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.2) (1.26.4)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.2) (2.32.5)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.2) (11.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.1.2) (3.0.3)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.16.2) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.16.2) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.16.2) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.16.2) (2025.3.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.16.2) (2022.3.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.16.2) (2.4.1)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.2) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.2) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.2) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.2) (2025.10.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.1.2) (1.3.0)\r\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.16.2) (2025.3.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.16.2) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.16.2) (2022.3.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision==0.16.2) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision==0.16.2) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision==0.16.2) (2024.2.0)\r\n",
      "Installing collected packages: triton, torch, torchvision\r\n",
      "  Attempting uninstall: triton\r\n",
      "    Found existing installation: triton 3.2.0\r\n",
      "    Uninstalling triton-3.2.0:\r\n",
      "      Successfully uninstalled triton-3.2.0\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 2.6.0+cu124\r\n",
      "    Uninstalling torch-2.6.0+cu124:\r\n",
      "      Successfully uninstalled torch-2.6.0+cu124\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.21.0+cu124\r\n",
      "    Uninstalling torchvision-0.21.0+cu124:\r\n",
      "      Successfully uninstalled torchvision-0.21.0+cu124\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.1.2+cu118 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed torch-2.1.2+cu118 torchvision-0.16.2+cu118 triton-2.1.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.1.2 torchvision==0.16.2 --extra-index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da1a0d7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T00:10:00.177671Z",
     "iopub.status.busy": "2025-11-30T00:10:00.177364Z",
     "iopub.status.idle": "2025-11-30T00:11:06.786882Z",
     "shell.execute_reply": "2025-11-30T00:11:06.786105Z"
    },
    "papermill": {
     "duration": 66.652907,
     "end_time": "2025-11-30T00:11:06.788917",
     "exception": false,
     "start_time": "2025-11-30T00:10:00.136010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openmim\r\n",
      "  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\r\n",
      "Requirement already satisfied: Click in /usr/local/lib/python3.11/dist-packages (from openmim) (8.3.0)\r\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from openmim) (0.4.6)\r\n",
      "Collecting model-index (from openmim)\r\n",
      "  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\r\n",
      "Collecting opendatalab (from openmim)\r\n",
      "  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from openmim) (2.2.3)\r\n",
      "Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.11/dist-packages (from openmim) (24.1.2)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from openmim) (2.32.5)\r\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from openmim) (14.2.0)\r\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from openmim) (0.9.0)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from model-index->openmim) (6.0.3)\r\n",
      "Requirement already satisfied: markdown in /usr/local/lib/python3.11/dist-packages (from model-index->openmim) (3.8.2)\r\n",
      "Collecting ordered-set (from model-index->openmim)\r\n",
      "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\r\n",
      "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.11/dist-packages (from opendatalab->openmim) (3.23.0)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from opendatalab->openmim) (4.67.1)\r\n",
      "Collecting openxlab (from opendatalab->openmim)\r\n",
      "  Downloading openxlab-0.1.3-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->openmim) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->openmim) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->openmim) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->openmim) (2025.10.5)\r\n",
      "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->openmim) (1.26.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->openmim) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->openmim) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->openmim) (2025.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->openmim) (4.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->openmim) (2.19.2)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->openmim) (0.1.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->openmim) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->openmim) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->openmim) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->openmim) (2025.3.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->openmim) (2022.3.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->openmim) (2.4.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->openmim) (1.17.0)\r\n",
      "Collecting filelock~=3.14.0 (from openxlab->opendatalab->openmim)\r\n",
      "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim)\r\n",
      "  Downloading oss2-2.17.0.tar.gz (259 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Collecting packaging~=24.0 (from openxlab->opendatalab->openmim)\r\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\r\n",
      "Collecting pytz>=2020.1 (from pandas->openmim)\r\n",
      "  Downloading pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\r\n",
      "Collecting requests (from openmim)\r\n",
      "  Downloading requests-2.28.2-py3-none-any.whl.metadata (4.6 kB)\r\n",
      "Collecting rich (from openmim)\r\n",
      "  Downloading rich-13.4.2-py3-none-any.whl.metadata (18 kB)\r\n",
      "Collecting setuptools~=60.2.0 (from openxlab->opendatalab->openmim)\r\n",
      "  Downloading setuptools-60.2.0-py3-none-any.whl.metadata (5.1 kB)\r\n",
      "Collecting tqdm (from opendatalab->openmim)\r\n",
      "  Downloading tqdm-4.65.2-py3-none-any.whl.metadata (56 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting urllib3<1.27,>=1.21.1 (from requests->openmim)\r\n",
      "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting crcmod>=1.7 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\r\n",
      "  Downloading crcmod-1.7.tar.gz (89 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Collecting aliyun-python-sdk-kms>=2.4.1 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\r\n",
      "  Downloading aliyun_python_sdk_kms-2.16.5-py2.py3-none-any.whl.metadata (1.5 kB)\r\n",
      "Collecting aliyun-python-sdk-core>=2.13.12 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\r\n",
      "  Downloading aliyun-python-sdk-core-2.16.0.tar.gz (449 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.6/449.6 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas->openmim) (2025.3.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas->openmim) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas->openmim) (2022.3.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas->openmim) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas->openmim) (2024.2.0)\r\n",
      "Collecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim)\r\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl.metadata (8.0 kB)\r\n",
      "Requirement already satisfied: cryptography>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (46.0.3)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas->openmim) (2024.2.0)\r\n",
      "Requirement already satisfied: cffi>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from cryptography>=3.0.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (2.0.0)\r\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=2.0.0->cryptography>=3.0.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (2.23)\r\n",
      "Downloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading model_index-0.1.11-py3-none-any.whl (34 kB)\r\n",
      "Downloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\r\n",
      "Downloading openxlab-0.1.3-py3-none-any.whl (314 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.5/314.5 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading requests-2.28.2-py3-none-any.whl (62 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading rich-13.4.2-py3-none-any.whl (239 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pytz-2023.4-py2.py3-none-any.whl (506 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.5/506.5 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tqdm-4.65.2-py3-none-any.whl (77 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\r\n",
      "Downloading filelock-3.14.0-py3-none-any.whl (12 kB)\r\n",
      "Downloading packaging-24.2-py3-none-any.whl (65 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading setuptools-60.2.0-py3-none-any.whl (953 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading aliyun_python_sdk_kms-2.16.5-py2.py3-none-any.whl (99 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.5/99.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\r\n",
      "Building wheels for collected packages: oss2, aliyun-python-sdk-core, crcmod\r\n",
      "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for oss2: filename=oss2-2.17.0-py3-none-any.whl size=112371 sha256=ff8ed233b8f187233a3c7d0ae27c72b1c9dd0eb58027dd761eb6d6e08d8b0419\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/42/79/aa/3671e313c27de35211d345d7a9d8ccb7dde515cf05edba75df\r\n",
      "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.16.0-py3-none-any.whl size=535315 sha256=e790fb72dba4c99d488e92f4316c5c3b607ff83f6c06eeeb22548d96e40e00cc\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/2b/9a/95/60f111d2a488c5f7f7ed2a96ce407ea57ec7393ddfdec8c956\r\n",
      "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for crcmod: filename=crcmod-1.7-cp311-cp311-linux_x86_64.whl size=31657 sha256=e2d255f35fddf1107064e1eb4ad44179bd0d0de6431cebaa25da4dbc99e71d8e\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/23/94/7a/8cb7d14597e6395ce969933f01aed9ea8fa5f5b4d4c8a61e99\r\n",
      "Successfully built oss2 aliyun-python-sdk-core crcmod\r\n",
      "Installing collected packages: pytz, crcmod, urllib3, tqdm, setuptools, packaging, ordered-set, jmespath, filelock, rich, requests, model-index, aliyun-python-sdk-core, aliyun-python-sdk-kms, oss2, openxlab, opendatalab, openmim\r\n",
      "  Attempting uninstall: pytz\r\n",
      "    Found existing installation: pytz 2025.2\r\n",
      "    Uninstalling pytz-2025.2:\r\n",
      "      Successfully uninstalled pytz-2025.2\r\n",
      "  Attempting uninstall: urllib3\r\n",
      "    Found existing installation: urllib3 2.5.0\r\n",
      "    Uninstalling urllib3-2.5.0:\r\n",
      "      Successfully uninstalled urllib3-2.5.0\r\n",
      "  Attempting uninstall: tqdm\r\n",
      "    Found existing installation: tqdm 4.67.1\r\n",
      "    Uninstalling tqdm-4.67.1:\r\n",
      "      Successfully uninstalled tqdm-4.67.1\r\n",
      "  Attempting uninstall: setuptools\r\n",
      "    Found existing installation: setuptools 75.2.0\r\n",
      "    Uninstalling setuptools-75.2.0:\r\n",
      "      Successfully uninstalled setuptools-75.2.0\r\n",
      "  Attempting uninstall: packaging\r\n",
      "    Found existing installation: packaging 25.0\r\n",
      "    Uninstalling packaging-25.0:\r\n",
      "      Successfully uninstalled packaging-25.0\r\n",
      "  Attempting uninstall: jmespath\r\n",
      "    Found existing installation: jmespath 1.0.1\r\n",
      "    Uninstalling jmespath-1.0.1:\r\n",
      "      Successfully uninstalled jmespath-1.0.1\r\n",
      "  Attempting uninstall: filelock\r\n",
      "    Found existing installation: filelock 3.20.0\r\n",
      "    Uninstalling filelock-3.20.0:\r\n",
      "      Successfully uninstalled filelock-3.20.0\r\n",
      "  Attempting uninstall: rich\r\n",
      "    Found existing installation: rich 14.2.0\r\n",
      "    Uninstalling rich-14.2.0:\r\n",
      "      Successfully uninstalled rich-14.2.0\r\n",
      "  Attempting uninstall: requests\r\n",
      "    Found existing installation: requests 2.32.5\r\n",
      "    Uninstalling requests-2.32.5:\r\n",
      "      Successfully uninstalled requests-2.32.5\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "datasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "datasets 4.4.1 requires requests>=2.32.2, but you have requests 2.28.2 which is incompatible.\r\n",
      "datasets 4.4.1 requires tqdm>=4.66.3, but you have tqdm 4.65.2 which is incompatible.\r\n",
      "google-adk 1.18.0 requires requests<3.0.0,>=2.32.4, but you have requests 2.28.2 which is incompatible.\r\n",
      "featuretools 1.31.0 requires tqdm>=4.66.3, but you have tqdm 4.65.2 which is incompatible.\r\n",
      "s3fs 2025.3.0 requires fsspec==2025.3.0.*, but you have fsspec 2025.10.0 which is incompatible.\r\n",
      "ray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\r\n",
      "jupyterlab-server 2.28.0 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\r\n",
      "preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.2 which is incompatible.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.28.2 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "ibis-framework 9.5.0 requires toolz<1,>=0.11, but you have toolz 1.1.0 which is incompatible.\r\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.1.2+cu118 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\r\n",
      "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.0 which is incompatible.\r\n",
      "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\r\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\r\n",
      "yfinance 0.2.65 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\r\n",
      "pytensor 2.31.7 requires filelock>=3.15, but you have filelock 3.14.0 which is incompatible.\r\n",
      "sphinx 8.2.3 requires requests>=2.30.0, but you have requests 2.28.2 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\r\n",
      "jupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\r\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "dataproc-spark-connect 0.8.3 requires tqdm>=4.67, but you have tqdm 4.65.2 which is incompatible.\r\n",
      "pymc 5.25.1 requires rich>=13.7.1, but you have rich 13.4.2 which is incompatible.\r\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\r\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed aliyun-python-sdk-core-2.16.0 aliyun-python-sdk-kms-2.16.5 crcmod-1.7 filelock-3.14.0 jmespath-0.10.0 model-index-0.1.11 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.1.3 ordered-set-4.1.0 oss2-2.17.0 packaging-24.2 pytz-2023.4 requests-2.28.2 rich-13.4.2 setuptools-60.2.0 tqdm-4.65.2 urllib3-1.26.20\r\n",
      "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.1.0/index.html\r\n",
      "Collecting mmengine==0.10.4\r\n",
      "  Downloading mmengine-0.10.4-py3-none-any.whl.metadata (20 kB)\r\n",
      "Collecting addict (from mmengine==0.10.4)\r\n",
      "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mmengine==0.10.4) (3.7.2)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mmengine==0.10.4) (1.26.4)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from mmengine==0.10.4) (6.0.3)\r\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from mmengine==0.10.4) (13.4.2)\r\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from mmengine==0.10.4) (3.1.0)\r\n",
      "Collecting yapf (from mmengine==0.10.4)\r\n",
      "  Downloading yapf-0.43.0-py3-none-any.whl.metadata (46 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.11/dist-packages (from mmengine==0.10.4) (4.12.0.88)\r\n",
      "Collecting numpy (from mmengine==0.10.4)\r\n",
      "  Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine==0.10.4) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine==0.10.4) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine==0.10.4) (4.59.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine==0.10.4) (1.4.8)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine==0.10.4) (24.2)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine==0.10.4) (11.3.0)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine==0.10.4) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine==0.10.4) (2.9.0.post0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->mmengine==0.10.4) (4.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->mmengine==0.10.4) (2.19.2)\r\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.11/dist-packages (from yapf->mmengine==0.10.4) (4.5.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine==0.10.4) (0.1.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine==0.10.4) (1.17.0)\r\n",
      "Downloading mmengine-0.10.4-py3-none-any.whl (451 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m451.7/451.7 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\r\n",
      "Downloading yapf-0.43.0-py3-none-any.whl (256 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.2/256.2 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: addict, yapf, numpy, mmengine\r\n",
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 1.26.4\r\n",
      "    Uninstalling numpy-1.26.4:\r\n",
      "      Successfully uninstalled numpy-1.26.4\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\r\n",
      "datasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "datasets 4.4.1 requires requests>=2.32.2, but you have requests 2.28.2 which is incompatible.\r\n",
      "datasets 4.4.1 requires tqdm>=4.66.3, but you have tqdm 4.65.2 which is incompatible.\r\n",
      "featuretools 1.31.0 requires tqdm>=4.66.3, but you have tqdm 4.65.2 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires numpy<2.2,>=1.16.0, but you have numpy 2.2.6 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.28.2 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\r\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "yfinance 0.2.65 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\r\n",
      "pytensor 2.31.7 requires filelock>=3.15, but you have filelock 3.14.0 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "pymc 5.25.1 requires rich>=13.7.1, but you have rich 13.4.2 which is incompatible.\r\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed addict-2.4.0 mmengine-0.10.4 numpy-2.2.6 yapf-0.43.0\r\n",
      "\r\n",
      "A module that was compiled using NumPy 1.x cannot be run in\r\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\r\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\r\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\r\n",
      "\r\n",
      "If you are a user of the module, the easiest solution will be to\r\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\r\n",
      "We expect that some modules will need time to support NumPy 2.\r\n",
      "\r\n",
      "Traceback (most recent call last):  File \"/usr/local/bin/mim\", line 8, in <module>\r\n",
      "    sys.exit(cli())\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1462, in __call__\r\n",
      "    return self.main(*args, **kwargs)\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1383, in main\r\n",
      "    rv = self.invoke(ctx)\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1850, in invoke\r\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1246, in invoke\r\n",
      "    return ctx.invoke(self.callback, **ctx.params)\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 814, in invoke\r\n",
      "    return callback(*args, **kwargs)\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/mim/commands/install.py\", line 72, in cli\r\n",
      "    exit_code = install(list(args), index_url=index_url, is_yes=is_yes)\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/mim/commands/install.py\", line 128, in install\r\n",
      "    install_args += ['-f', get_mmcv_full_find_link(mmcv_base_url)]\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/mim/commands/install.py\", line 165, in get_mmcv_full_find_link\r\n",
      "    torch_v, cuda_v = get_torch_cuda_version()\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/mim/utils/utils.py\", line 338, in get_torch_cuda_version\r\n",
      "    import torch\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1382, in <module>\r\n",
      "    from .functional import *  # noqa: F403\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 7, in <module>\r\n",
      "    import torch.nn.functional as F\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\r\n",
      "    from .modules import *  # noqa: F403\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\r\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\r\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\r\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\r\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\r\n",
      "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.1.0/index.html\r\n",
      "Collecting mmcv==2.1.0\r\n",
      "  Downloading https://download.openmmlab.com/mmcv/dist/cu118/torch2.1.0/mmcv-2.1.0-cp311-cp311-manylinux1_x86_64.whl (99.4 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.4/99.4 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: addict in /usr/local/lib/python3.11/dist-packages (from mmcv==2.1.0) (2.4.0)\r\n",
      "Requirement already satisfied: mmengine>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from mmcv==2.1.0) (0.10.4)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mmcv==2.1.0) (2.2.6)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mmcv==2.1.0) (24.2)\r\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from mmcv==2.1.0) (11.3.0)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from mmcv==2.1.0) (6.0.3)\r\n",
      "Requirement already satisfied: yapf in /usr/local/lib/python3.11/dist-packages (from mmcv==2.1.0) (0.43.0)\r\n",
      "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.11/dist-packages (from mmcv==2.1.0) (4.12.0.88)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mmengine>=0.3.0->mmcv==2.1.0) (3.7.2)\r\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from mmengine>=0.3.0->mmcv==2.1.0) (13.4.2)\r\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from mmengine>=0.3.0->mmcv==2.1.0) (3.1.0)\r\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.11/dist-packages (from yapf->mmcv==2.1.0) (4.5.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.1.0) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.1.0) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.1.0) (4.59.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.1.0) (1.4.8)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.1.0) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.1.0) (2.9.0.post0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->mmengine>=0.3.0->mmcv==2.1.0) (4.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->mmengine>=0.3.0->mmcv==2.1.0) (2.19.2)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.3.0->mmcv==2.1.0) (0.1.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.3.0->mmcv==2.1.0) (1.17.0)\r\n",
      "Installing collected packages: mmcv\r\n",
      "Successfully installed mmcv-2.1.0\r\n",
      "\r\n",
      "A module that was compiled using NumPy 1.x cannot be run in\r\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\r\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\r\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\r\n",
      "\r\n",
      "If you are a user of the module, the easiest solution will be to\r\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\r\n",
      "We expect that some modules will need time to support NumPy 2.\r\n",
      "\r\n",
      "Traceback (most recent call last):  File \"/usr/local/bin/mim\", line 8, in <module>\r\n",
      "    sys.exit(cli())\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1462, in __call__\r\n",
      "    return self.main(*args, **kwargs)\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1383, in main\r\n",
      "    rv = self.invoke(ctx)\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1850, in invoke\r\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1246, in invoke\r\n",
      "    return ctx.invoke(self.callback, **ctx.params)\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 814, in invoke\r\n",
      "    return callback(*args, **kwargs)\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/mim/commands/install.py\", line 72, in cli\r\n",
      "    exit_code = install(list(args), index_url=index_url, is_yes=is_yes)\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/mim/commands/install.py\", line 128, in install\r\n",
      "    install_args += ['-f', get_mmcv_full_find_link(mmcv_base_url)]\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/mim/commands/install.py\", line 165, in get_mmcv_full_find_link\r\n",
      "    torch_v, cuda_v = get_torch_cuda_version()\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/mim/utils/utils.py\", line 338, in get_torch_cuda_version\r\n",
      "    import torch\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1382, in <module>\r\n",
      "    from .functional import *  # noqa: F403\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 7, in <module>\r\n",
      "    import torch.nn.functional as F\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\r\n",
      "    from .modules import *  # noqa: F403\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\r\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\r\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\r\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\r\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\r\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\r\n",
      "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.1.0/index.html\r\n",
      "Collecting mmdet==3.3.0\r\n",
      "  Downloading mmdet-3.3.0-py3-none-any.whl.metadata (29 kB)\r\n",
      "Ignoring mmcv: markers 'extra == \"mim\"' don't match your environment\r\n",
      "Ignoring mmengine: markers 'extra == \"mim\"' don't match your environment\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mmdet==3.3.0) (3.7.2)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mmdet==3.3.0) (2.2.6)\r\n",
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (from mmdet==3.3.0) (2.0.10)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from mmdet==3.3.0) (1.15.3)\r\n",
      "Requirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (from mmdet==3.3.0) (2.1.2)\r\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from mmdet==3.3.0) (1.17.0)\r\n",
      "Collecting terminaltables (from mmdet==3.3.0)\r\n",
      "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl.metadata (3.5 kB)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mmdet==3.3.0) (4.65.2)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmdet==3.3.0) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmdet==3.3.0) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmdet==3.3.0) (4.59.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmdet==3.3.0) (1.4.8)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmdet==3.3.0) (24.2)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmdet==3.3.0) (11.3.0)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmdet==3.3.0) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mmdet==3.3.0) (2.9.0.post0)\r\n",
      "Downloading mmdet-3.3.0-py3-none-any.whl (2.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\r\n",
      "Installing collected packages: terminaltables, mmdet\r\n",
      "Successfully installed mmdet-3.3.0 terminaltables-3.1.10\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U openmim\n",
    "!mim install mmengine==0.10.4\n",
    "!mim install mmcv==2.1.0\n",
    "!mim install mmdet==3.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5fb1333",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T00:11:06.896663Z",
     "iopub.status.busy": "2025-11-30T00:11:06.896362Z",
     "iopub.status.idle": "2025-11-30T00:11:06.900855Z",
     "shell.execute_reply": "2025-11-30T00:11:06.900270Z"
    },
    "papermill": {
     "duration": 0.060016,
     "end_time": "2025-11-30T00:11:06.901878",
     "exception": false,
     "start_time": "2025-11-30T00:11:06.841862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de89ef8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T00:11:07.007801Z",
     "iopub.status.busy": "2025-11-30T00:11:07.007525Z",
     "iopub.status.idle": "2025-11-30T00:11:08.603982Z",
     "shell.execute_reply": "2025-11-30T00:11:08.603005Z"
    },
    "papermill": {
     "duration": 1.650802,
     "end_time": "2025-11-30T00:11:08.605318",
     "exception": false,
     "start_time": "2025-11-30T00:11:06.954516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.1.2+cu118\n",
      "CUDA available: True\n",
      "CUDA version (compiled): 11.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version (compiled):\", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "594b8779",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T00:11:08.712290Z",
     "iopub.status.busy": "2025-11-30T00:11:08.711576Z",
     "iopub.status.idle": "2025-11-30T00:11:15.014677Z",
     "shell.execute_reply": "2025-11-30T00:11:15.013750Z"
    },
    "papermill": {
     "duration": 6.357478,
     "end_time": "2025-11-30T00:11:15.015944",
     "exception": false,
     "start_time": "2025-11-30T00:11:08.658466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.26.4\r\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: numpy\r\n",
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 2.2.6\r\n",
      "    Uninstalling numpy-2.2.6:\r\n",
      "      Successfully uninstalled numpy-2.2.6\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "datasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "datasets 4.4.1 requires requests>=2.32.2, but you have requests 2.28.2 which is incompatible.\r\n",
      "datasets 4.4.1 requires tqdm>=4.66.3, but you have tqdm 4.65.2 which is incompatible.\r\n",
      "featuretools 1.31.0 requires tqdm>=4.66.3, but you have tqdm 4.65.2 which is incompatible.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.28.2 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\r\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\r\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "yfinance 0.2.65 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\r\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\r\n",
      "pytensor 2.31.7 requires filelock>=3.15, but you have filelock 3.14.0 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "pymc 5.25.1 requires rich>=13.7.1, but you have rich 13.4.2 which is incompatible.\r\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4\r\n",
      "1.26.4\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.26.4\n",
    "\n",
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "588bbd7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T00:11:15.125362Z",
     "iopub.status.busy": "2025-11-30T00:11:15.125013Z",
     "iopub.status.idle": "2025-11-30T00:11:27.961385Z",
     "shell.execute_reply": "2025-11-30T00:11:27.960502Z"
    },
    "papermill": {
     "duration": 12.892477,
     "end_time": "2025-11-30T00:11:27.962575",
     "exception": false,
     "start_time": "2025-11-30T00:11:15.070098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.30.2\r\n",
      "  Downloading transformers-4.30.2-py3-none-any.whl.metadata (113 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.6/113.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (3.14.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (0.36.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (24.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (6.0.3)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (2025.11.3)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (2.28.2)\r\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.30.2)\r\n",
      "  Downloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (0.5.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (4.65.2)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2) (2025.10.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2) (4.15.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2) (1.2.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.2) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.2) (3.11)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.2) (1.26.20)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.2) (2025.10.5)\r\n",
      "Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: tokenizers, transformers\r\n",
      "  Attempting uninstall: tokenizers\r\n",
      "    Found existing installation: tokenizers 0.21.2\r\n",
      "    Uninstalling tokenizers-0.21.2:\r\n",
      "      Successfully uninstalled tokenizers-0.21.2\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.53.3\r\n",
      "    Uninstalling transformers-4.53.3:\r\n",
      "      Successfully uninstalled transformers-4.53.3\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "kaggle-environments 1.18.0 requires transformers>=4.33.1, but you have transformers 4.30.2 which is incompatible.\r\n",
      "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.30.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed tokenizers-0.13.3 transformers-4.30.2\r\n",
      "4.30.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.30.2\n",
    "\n",
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3940470e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T00:11:28.070997Z",
     "iopub.status.busy": "2025-11-30T00:11:28.069915Z",
     "iopub.status.idle": "2025-11-30T00:11:28.559761Z",
     "shell.execute_reply": "2025-11-30T00:11:28.558893Z"
    },
    "papermill": {
     "duration": 0.544673,
     "end_time": "2025-11-30T00:11:28.560942",
     "exception": false,
     "start_time": "2025-11-30T00:11:28.016269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMCV: 2.1.0\n",
      "MMDetection: 3.3.0\n",
      "MMEngine: 0.10.4\n"
     ]
    }
   ],
   "source": [
    "import mmcv\n",
    "import mmdet\n",
    "import mmengine\n",
    "\n",
    "print(\"MMCV:\", mmcv.__version__)\n",
    "print(\"MMDetection:\", mmdet.__version__)\n",
    "print(\"MMEngine:\", mmengine.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18bd4529",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T00:11:28.682370Z",
     "iopub.status.busy": "2025-11-30T00:11:28.682063Z",
     "iopub.status.idle": "2025-11-30T00:11:29.989330Z",
     "shell.execute_reply": "2025-11-30T00:11:29.988516Z"
    },
    "papermill": {
     "duration": 1.371322,
     "end_time": "2025-11-30T00:11:29.990492",
     "exception": false,
     "start_time": "2025-11-30T00:11:28.619170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torchvision: 0.16.2+cu118\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "print(\"Torchvision:\", torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53303683",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T00:11:30.100378Z",
     "iopub.status.busy": "2025-11-30T00:11:30.099978Z",
     "iopub.status.idle": "2025-11-30T00:11:30.359779Z",
     "shell.execute_reply": "2025-11-30T00:11:30.358895Z"
    },
    "papermill": {
     "duration": 0.315862,
     "end_time": "2025-11-30T00:11:30.361125",
     "exception": false,
     "start_time": "2025-11-30T00:11:30.045263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p data\n",
    "!ln -s /kaggle/input/usis10k/USIS10K ./data/USIS10\n",
    "#!ls -R data/USIS10K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f09a51e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T00:11:30.568569Z",
     "iopub.status.busy": "2025-11-30T00:11:30.568257Z",
     "iopub.status.idle": "2025-11-30T00:11:31.078603Z",
     "shell.execute_reply": "2025-11-30T00:11:31.077552Z"
    },
    "papermill": {
     "duration": 0.566402,
     "end_time": "2025-11-30T00:11:31.080118",
     "exception": false,
     "start_time": "2025-11-30T00:11:30.513716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_agnostic_model.pth  multi_class_model.pth\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p checkpoints\n",
    "\n",
    "!ln -s /kaggle/input/pre-trained-models/class_agnostic_model.pth ./checkpoints/class_agnostic_model.pth\n",
    "!ln -s /kaggle/input/pre-trained-models/multi_class_model.pth ./checkpoints/multi_class_model.pth\n",
    "\n",
    "!ls checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1684c42f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T00:11:31.194362Z",
     "iopub.status.busy": "2025-11-30T00:11:31.193674Z",
     "iopub.status.idle": "2025-11-30T00:11:31.327657Z",
     "shell.execute_reply": "2025-11-30T00:11:31.326643Z"
    },
    "papermill": {
     "duration": 0.193322,
     "end_time": "2025-11-30T00:11:31.329134",
     "exception": false,
     "start_time": "2025-11-30T00:11:31.135812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /kaggle/working/USIS10K\n",
      "checkpoints  LICENSE   README.md\t setup.py  vis_infer.py\r\n",
      "data\t     pretrain  requirements.txt  tests\r\n",
      "figs\t     project   setup.cfg\t tools\r\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "os.chdir('/kaggle/working/USIS10K')\n",
    "\n",
    "if os.getcwd() not in sys.path:\n",
    "    sys.path.append(os.getcwd())\n",
    "\n",
    "print(\"CWD:\", os.getcwd())\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91871db8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T00:11:31.439328Z",
     "iopub.status.busy": "2025-11-30T00:11:31.438619Z",
     "iopub.status.idle": "2025-11-30T00:11:39.990838Z",
     "shell.execute_reply": "2025-11-30T00:11:39.989867Z"
    },
    "papermill": {
     "duration": 8.609224,
     "end_time": "2025-11-30T00:11:39.992310",
     "exception": false,
     "start_time": "2025-11-30T00:11:31.383086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.30.2\r\n",
      "Uninstalling transformers-4.30.2:\r\n",
      "  Successfully uninstalled transformers-4.30.2\r\n",
      "Collecting transformers==4.30.2\r\n",
      "  Using cached transformers-4.30.2-py3-none-any.whl.metadata (113 kB)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (3.14.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (0.36.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (24.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (6.0.3)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (2025.11.3)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (2.28.2)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (0.13.3)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (0.5.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (4.65.2)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2) (2025.10.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2) (4.15.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2) (1.2.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.2) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.2) (3.11)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.2) (1.26.20)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.2) (2025.10.5)\r\n",
      "Using cached transformers-4.30.2-py3-none-any.whl (7.2 MB)\r\n",
      "Installing collected packages: transformers\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "kaggle-environments 1.18.0 requires transformers>=4.33.1, but you have transformers 4.30.2 which is incompatible.\r\n",
      "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.30.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed transformers-4.30.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y transformers\n",
    "!pip install transformers==4.30.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9fd687d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T00:11:40.100535Z",
     "iopub.status.busy": "2025-11-30T00:11:40.099888Z",
     "iopub.status.idle": "2025-11-30T00:11:56.167148Z",
     "shell.execute_reply": "2025-11-30T00:11:56.166322Z"
    },
    "papermill": {
     "duration": 16.122541,
     "end_time": "2025-11-30T00:11:56.168337",
     "exception": false,
     "start_time": "2025-11-30T00:11:40.045796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: kaggle-environments 1.18.0\r\n",
      "Uninstalling kaggle-environments-1.18.0:\r\n",
      "  Successfully uninstalled kaggle-environments-1.18.0\r\n",
      "Found existing installation: sentence-transformers 4.1.0\r\n",
      "Uninstalling sentence-transformers-4.1.0:\r\n",
      "  Successfully uninstalled sentence-transformers-4.1.0\r\n",
      "Found existing installation: transformers 4.30.2\r\n",
      "Uninstalling transformers-4.30.2:\r\n",
      "  Successfully uninstalled transformers-4.30.2\r\n",
      "Found existing installation: peft 0.16.0\r\n",
      "Uninstalling peft-0.16.0:\r\n",
      "  Successfully uninstalled peft-0.16.0\r\n",
      "Collecting transformers==4.30.2\r\n",
      "  Using cached transformers-4.30.2-py3-none-any.whl.metadata (113 kB)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (3.14.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (0.36.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (24.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (6.0.3)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (2025.11.3)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (2.28.2)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (0.13.3)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (0.5.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (4.65.2)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2) (2025.10.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2) (4.15.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2) (1.2.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.2) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.2) (3.11)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.2) (1.26.20)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.2) (2025.10.5)\r\n",
      "Using cached transformers-4.30.2-py3-none-any.whl (7.2 MB)\r\n",
      "Installing collected packages: transformers\r\n",
      "Successfully installed transformers-4.30.2\r\n",
      "Collecting peft==0.4.0\r\n",
      "  Downloading peft-0.4.0-py3-none-any.whl.metadata (21 kB)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft==0.4.0) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.4.0) (24.2)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft==0.4.0) (7.1.3)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft==0.4.0) (6.0.3)\r\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.4.0) (2.1.2+cu118)\r\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft==0.4.0) (4.30.2)\r\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from peft==0.4.0) (1.9.0)\r\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft==0.4.0) (0.5.3)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.4.0) (3.14.0)\r\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.4.0) (4.15.0)\r\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.4.0) (1.13.1)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.4.0) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.4.0) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.4.0) (2025.10.0)\r\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.4.0) (2.1.0)\r\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate->peft==0.4.0) (0.36.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft==0.4.0) (2025.11.3)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers->peft==0.4.0) (2.28.2)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from transformers->peft==0.4.0) (0.13.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers->peft==0.4.0) (4.65.2)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate->peft==0.4.0) (1.2.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft==0.4.0) (3.0.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->peft==0.4.0) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->peft==0.4.0) (3.11)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->peft==0.4.0) (1.26.20)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->peft==0.4.0) (2025.10.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.13.0->peft==0.4.0) (1.3.0)\r\n",
      "Downloading peft-0.4.0-py3-none-any.whl (72 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: peft\r\n",
      "Successfully installed peft-0.4.0\r\n",
      "4.30.2\n",
      "0.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y kaggle-environments\n",
    "!pip uninstall -y sentence-transformers\n",
    "!pip uninstall -y transformers\n",
    "!pip uninstall -y peft\n",
    "\n",
    "!pip install transformers==4.30.2\n",
    "!pip install peft==0.4.0\n",
    "\n",
    "import transformers, peft\n",
    "print(transformers.__version__)\n",
    "print(peft.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f74478d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T00:11:56.282114Z",
     "iopub.status.busy": "2025-11-30T00:11:56.281540Z",
     "iopub.status.idle": "2025-11-30T00:11:56.286019Z",
     "shell.execute_reply": "2025-11-30T00:11:56.285366Z"
    },
    "papermill": {
     "duration": 0.063297,
     "end_time": "2025-11-30T00:11:56.287137",
     "exception": false,
     "start_time": "2025-11-30T00:11:56.223840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/kaggle/working/USIS10K')\n",
    "sys.path.append('/kaggle/working/USIS10K/project')\n",
    "sys.path.append('/kaggle/working/USIS10K/project/our')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acd2db69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T00:11:56.399064Z",
     "iopub.status.busy": "2025-11-30T00:11:56.398778Z",
     "iopub.status.idle": "2025-11-30T00:11:56.404345Z",
     "shell.execute_reply": "2025-11-30T00:11:56.403614Z"
    },
    "papermill": {
     "duration": 0.063499,
     "end_time": "2025-11-30T00:11:56.405505",
     "exception": false,
     "start_time": "2025-11-30T00:11:56.342006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6.33.0'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import google.protobuf\n",
    "google.protobuf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0a25b62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T00:11:56.516396Z",
     "iopub.status.busy": "2025-11-30T00:11:56.515989Z",
     "iopub.status.idle": "2025-11-30T00:12:11.741935Z",
     "shell.execute_reply": "2025-11-30T00:12:11.741142Z"
    },
    "papermill": {
     "duration": 15.282414,
     "end_time": "2025-11-30T00:12:11.743080",
     "exception": false,
     "start_time": "2025-11-30T00:11:56.460666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 00:11:58.350389: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764461518.527206      22 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764461518.575268      22 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/kaggle/working/USIS10K')\n",
    "sys.path.append('/kaggle/working/USIS10K/project')\n",
    "sys.path.append('/kaggle/working/USIS10K/project/our')\n",
    "\n",
    "import project.our.our_model.anchor\n",
    "print(\"SUCCESS!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95b9e47f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T00:12:11.859302Z",
     "iopub.status.busy": "2025-11-30T00:12:11.858257Z",
     "iopub.status.idle": "2025-11-30T00:12:12.273140Z",
     "shell.execute_reply": "2025-11-30T00:12:12.272482Z"
    },
    "papermill": {
     "duration": 0.47313,
     "end_time": "2025-11-30T00:12:12.274363",
     "exception": false,
     "start_time": "2025-11-30T00:12:11.801233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/USIS10K/project/our/configs/foreground_usis_train_patched.py'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mmengine\n",
    "\n",
    "# Patch visualization hook into config\n",
    "def patch_visualization_hook(config_path):\n",
    "    cfg = mmengine.Config.fromfile(config_path)\n",
    "\n",
    "    if 'default_hooks' not in cfg:\n",
    "        cfg.default_hooks = {}\n",
    "\n",
    "    # Insert VisualizationHook if not present\n",
    "    cfg.default_hooks['visualization'] = dict(type='VisualizationHook')\n",
    "\n",
    "    # Save patched config to temp file\n",
    "    patched_path = config_path.replace(\".py\", \"_patched.py\")\n",
    "    with open(patched_path, \"w\") as f:\n",
    "        f.write(cfg.pretty_text)\n",
    "\n",
    "    return patched_path\n",
    "\n",
    "# Patch your config\n",
    "patched_cfg = patch_visualization_hook(\n",
    "    \"/kaggle/working/USIS10K/project/our/configs/foreground_usis_train.py\"\n",
    ")\n",
    "\n",
    "patched_cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16705e7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T00:12:12.388073Z",
     "iopub.status.busy": "2025-11-30T00:12:12.387457Z",
     "iopub.status.idle": "2025-11-30T00:13:40.709565Z",
     "shell.execute_reply": "2025-11-30T00:13:40.708439Z"
    },
    "papermill": {
     "duration": 88.381049,
     "end_time": "2025-11-30T00:13:40.711442",
     "exception": false,
     "start_time": "2025-11-30T00:12:12.330393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/USIS10K/pretrain\n",
      "\u001b[33m⚠️  Warning: 'huggingface-cli download' is deprecated. Use 'hf download' instead.\u001b[0m\r\n",
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\r\n",
      "  warnings.warn(\r\n",
      "Fetching 5 files:   0%|                                   | 0/5 [00:00<?, ?it/s]Downloading 'pytorch_model.bin' to 'sam-vit-huge/.cache/huggingface/download/Q1p2l2BzM1m6P5jKvr8WTq1TUio=.9a14fd58481d203300024d94128edfce246b4b0db7e0b548ed52bf63578cbc38.incomplete'\r\n",
      "Downloading 'preprocessor_config.json' to 'sam-vit-huge/.cache/huggingface/download/PYH5dHjks7Ei0Yd3X0Z8xIwsCNQ=.732fbaf0c512b97d8d9161f51bc157bfb2873d12.incomplete'\r\n",
      "Downloading 'config.json' to 'sam-vit-huge/.cache/huggingface/download/8_PA_wEVGiVa2goH2H4KQOQpvVY=.97290178b40b269ecc23cb13c50e44c41c222df0.incomplete'\r\n",
      "Downloading '.gitattributes' to 'sam-vit-huge/.cache/huggingface/download/wPaCkH-WbT7GsmxMKKrNZTV4nSM=.c7d9f3332a950355d5a77d85000f05e6f45435ea.incomplete'\r\n",
      "Downloading 'README.md' to 'sam-vit-huge/.cache/huggingface/download/Xn7B-BWUGOee2Y6hCZtEhtFu4BE=.f8262b9d812fbba6dced46af33cd32c0560d5d6e.incomplete'\r\n",
      "\r\n",
      "config.json: 6.57kB [00:00, 16.3MB/s]\r\n",
      "Download complete. Moving file to sam-vit-huge/config.json\r\n",
      "\r\n",
      "preprocessor_config.json: 466B [00:00, 980kB/s]\r\n",
      "Download complete. Moving file to sam-vit-huge/preprocessor_config.json\r\n",
      "\r\n",
      ".gitattributes: 1.48kB [00:00, 9.41MB/s]\r\n",
      "Download complete. Moving file to sam-vit-huge/.gitattributes\r\n",
      "Fetching 5 files:  20%|█████▍                     | 1/5 [00:01<00:04,  1.17s/it]\r\n",
      "README.md: 6.89kB [00:00, 23.7MB/s]\r\n",
      "Download complete. Moving file to sam-vit-huge/README.md\r\n",
      "\r\n",
      "pytorch_model.bin:   0%|                            | 0.00/2.56G [00:00<?, ?B/s]\u001b[A\r\n",
      "pytorch_model.bin:   0%|                   | 10.5M/2.56G [00:00<01:49, 23.4MB/s]\u001b[A\r\n",
      "pytorch_model.bin:   1%|▏                  | 21.0M/2.56G [00:00<02:02, 20.8MB/s]\u001b[A\r\n",
      "pytorch_model.bin:   1%|▏                  | 31.5M/2.56G [00:01<01:45, 24.1MB/s]\u001b[A\r\n",
      "pytorch_model.bin:   2%|▎                  | 41.9M/2.56G [00:01<01:54, 22.1MB/s]\u001b[A\r\n",
      "pytorch_model.bin:   2%|▍                  | 52.4M/2.56G [00:02<01:43, 24.3MB/s]\u001b[A\r\n",
      "pytorch_model.bin:   2%|▍                  | 62.9M/2.56G [00:02<01:35, 26.2MB/s]\u001b[A\r\n",
      "pytorch_model.bin:   3%|▌                  | 73.4M/2.56G [00:03<01:57, 21.3MB/s]\u001b[A\r\n",
      "pytorch_model.bin:   3%|▌                  | 83.9M/2.56G [00:03<01:58, 21.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:   4%|▋                  | 94.4M/2.56G [00:04<02:30, 16.4MB/s]\u001b[A\r\n",
      "pytorch_model.bin:   4%|▊                   | 105M/2.56G [00:05<02:41, 15.2MB/s]\u001b[A\r\n",
      "pytorch_model.bin:   4%|▉                   | 115M/2.56G [00:06<02:29, 16.4MB/s]\u001b[A\r\n",
      "pytorch_model.bin:   5%|▉                   | 126M/2.56G [00:06<02:00, 20.2MB/s]\u001b[A\r\n",
      "pytorch_model.bin:   5%|█                   | 136M/2.56G [00:06<01:44, 23.3MB/s]\u001b[A\r\n",
      "pytorch_model.bin:   6%|█▏                  | 147M/2.56G [00:06<01:37, 24.9MB/s]\u001b[A\r\n",
      "pytorch_model.bin:   6%|█▏                  | 157M/2.56G [00:07<01:34, 25.4MB/s]\u001b[A\r\n",
      "pytorch_model.bin:   7%|█▎                  | 168M/2.56G [00:07<01:29, 26.8MB/s]\u001b[A\r\n",
      "pytorch_model.bin:   7%|█▍                  | 178M/2.56G [00:08<01:25, 27.8MB/s]\u001b[A\r\n",
      "pytorch_model.bin:   7%|█▍                  | 189M/2.56G [00:08<01:27, 27.1MB/s]\u001b[A\r\n",
      "pytorch_model.bin:   8%|█▌                  | 199M/2.56G [00:08<01:38, 23.9MB/s]\u001b[A\r\n",
      "pytorch_model.bin:   8%|█▋                  | 210M/2.56G [00:09<01:36, 24.3MB/s]\u001b[A\r\n",
      "pytorch_model.bin:   9%|█▋                  | 220M/2.56G [00:09<01:28, 26.5MB/s]\u001b[A\r\n",
      "pytorch_model.bin:   9%|█▊                  | 231M/2.56G [00:09<01:20, 29.1MB/s]\u001b[A\r\n",
      "pytorch_model.bin:   9%|█▉                  | 241M/2.56G [00:10<01:28, 26.4MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  10%|█▉                  | 252M/2.56G [00:10<01:27, 26.6MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  10%|██                  | 262M/2.56G [00:11<01:19, 28.8MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  11%|██▏                 | 273M/2.56G [00:11<01:18, 29.3MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  11%|██▏                 | 283M/2.56G [00:11<01:21, 28.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  11%|██▎                 | 294M/2.56G [00:12<01:23, 27.3MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  12%|██▎                 | 304M/2.56G [00:12<01:18, 28.9MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  12%|██▍                 | 315M/2.56G [00:12<01:17, 29.1MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  13%|██▌                 | 325M/2.56G [00:13<01:15, 29.7MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  13%|██▌                 | 336M/2.56G [00:13<01:27, 25.4MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  13%|██▋                 | 346M/2.56G [00:14<01:33, 23.7MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  14%|██▊                 | 357M/2.56G [00:14<01:31, 24.1MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  14%|██▊                 | 367M/2.56G [00:15<01:39, 22.1MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  15%|██▉                 | 377M/2.56G [00:15<01:28, 24.8MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  15%|███                 | 388M/2.56G [00:16<01:22, 26.5MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  16%|███                 | 398M/2.56G [00:16<01:18, 27.8MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  16%|███▏                | 409M/2.56G [00:16<01:16, 28.1MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  16%|███▎                | 419M/2.56G [00:17<01:17, 27.6MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  17%|███▎                | 430M/2.56G [00:17<01:23, 25.6MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  17%|███▍                | 440M/2.56G [00:17<01:12, 29.2MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  18%|███▌                | 451M/2.56G [00:18<01:20, 26.1MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  18%|███▌                | 461M/2.56G [00:18<01:14, 28.2MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  18%|███▋                | 472M/2.56G [00:19<01:25, 24.6MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  19%|███▊                | 482M/2.56G [00:19<01:27, 23.8MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  19%|███▊                | 493M/2.56G [00:20<01:27, 23.8MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  20%|███▉                | 503M/2.56G [00:20<01:10, 29.2MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  20%|████                | 514M/2.56G [00:20<01:10, 29.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  20%|████                | 524M/2.56G [00:20<01:10, 28.9MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  21%|████▏               | 535M/2.56G [00:21<01:10, 28.9MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  21%|████▎               | 545M/2.56G [00:21<01:09, 28.9MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  22%|████▎               | 556M/2.56G [00:22<01:12, 27.6MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  22%|████▍               | 566M/2.56G [00:22<01:24, 23.6MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  22%|████▍               | 577M/2.56G [00:23<01:29, 22.3MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  23%|████▌               | 587M/2.56G [00:23<01:31, 21.6MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  23%|████▋               | 598M/2.56G [00:24<01:30, 21.7MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  24%|████▋               | 608M/2.56G [00:24<01:20, 24.4MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  24%|████▊               | 619M/2.56G [00:25<01:21, 24.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  25%|████▉               | 629M/2.56G [00:25<01:14, 26.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  25%|████▉               | 640M/2.56G [00:25<01:05, 29.2MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  25%|█████               | 650M/2.56G [00:26<01:08, 28.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  26%|█████▏              | 661M/2.56G [00:26<01:05, 29.2MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  26%|█████▏              | 671M/2.56G [00:26<01:04, 29.6MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  27%|█████▎              | 682M/2.56G [00:27<01:06, 28.1MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  27%|█████▍              | 692M/2.56G [00:27<01:29, 20.9MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  27%|█████▍              | 703M/2.56G [00:28<01:30, 20.7MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  28%|█████▌              | 713M/2.56G [00:28<01:18, 23.5MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  28%|█████▋              | 724M/2.56G [00:29<01:20, 22.9MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  29%|█████▋              | 734M/2.56G [00:29<01:09, 26.3MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  29%|█████▊              | 744M/2.56G [00:29<01:10, 25.8MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  29%|█████▉              | 755M/2.56G [00:30<01:10, 25.7MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  30%|█████▉              | 765M/2.56G [00:30<01:08, 26.2MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  30%|██████              | 776M/2.56G [00:31<01:05, 27.4MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  31%|██████▏             | 786M/2.56G [00:31<01:00, 29.4MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  31%|██████▏             | 797M/2.56G [00:31<01:03, 27.8MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  31%|██████▎             | 807M/2.56G [00:32<01:00, 29.1MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  32%|██████▍             | 818M/2.56G [00:32<01:05, 26.8MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  32%|██████▍             | 828M/2.56G [00:33<01:09, 25.2MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  33%|██████▌             | 839M/2.56G [00:33<01:05, 26.5MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  33%|██████▌             | 849M/2.56G [00:33<01:02, 27.5MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  34%|██████▋             | 860M/2.56G [00:34<01:03, 26.9MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  34%|██████▊             | 870M/2.56G [00:34<00:56, 29.9MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  34%|██████▊             | 881M/2.56G [00:34<00:56, 30.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  35%|██████▉             | 891M/2.56G [00:35<00:56, 29.4MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  35%|███████             | 902M/2.56G [00:35<00:59, 28.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  36%|███████             | 912M/2.56G [00:35<00:55, 29.5MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  36%|███████▏            | 923M/2.56G [00:36<00:56, 29.1MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  36%|███████▎            | 933M/2.56G [00:36<00:54, 29.7MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  37%|███████▎            | 944M/2.56G [00:36<00:55, 29.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  37%|███████▍            | 954M/2.56G [00:37<00:57, 28.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  38%|███████▌            | 965M/2.56G [00:37<00:58, 27.6MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  38%|███████▌            | 975M/2.56G [00:38<00:54, 29.2MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  38%|███████▋            | 986M/2.56G [00:38<00:56, 28.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  39%|███████▊            | 996M/2.56G [00:39<01:09, 22.6MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  39%|███████▍           | 1.01G/2.56G [00:39<01:16, 20.4MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  40%|███████▌           | 1.02G/2.56G [00:40<01:05, 23.5MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  40%|███████▌           | 1.03G/2.56G [00:40<01:04, 24.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  40%|███████▋           | 1.04G/2.56G [00:40<01:07, 22.7MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  41%|███████▊           | 1.05G/2.56G [00:41<01:02, 24.1MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  41%|███████▊           | 1.06G/2.56G [00:41<00:59, 25.5MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  42%|███████▉           | 1.07G/2.56G [00:42<00:58, 25.7MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  42%|████████           | 1.08G/2.56G [00:43<01:29, 16.5MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  43%|████████           | 1.09G/2.56G [00:43<01:10, 21.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  43%|████████▏          | 1.10G/2.56G [00:43<00:58, 25.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  43%|████████▏          | 1.11G/2.56G [00:43<00:51, 28.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  44%|████████▎          | 1.12G/2.56G [00:44<00:44, 32.2MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  44%|████████▍          | 1.13G/2.56G [00:44<00:40, 35.7MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  45%|████████▍          | 1.14G/2.56G [00:44<00:38, 36.7MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  45%|████████▌          | 1.15G/2.56G [00:44<00:35, 39.8MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  45%|████████▌          | 1.16G/2.56G [00:45<00:33, 41.4MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  46%|████████▋          | 1.17G/2.56G [00:45<00:31, 44.5MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  46%|████████▊          | 1.18G/2.56G [00:45<00:30, 45.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  47%|████████▊          | 1.20G/2.56G [00:45<00:30, 45.3MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  47%|████████▉          | 1.21G/2.56G [00:45<00:28, 47.9MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  47%|█████████          | 1.22G/2.56G [00:46<00:30, 43.9MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  48%|█████████          | 1.23G/2.56G [00:46<00:30, 44.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  48%|█████████▏         | 1.24G/2.56G [00:46<00:29, 45.1MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  49%|█████████▏         | 1.25G/2.56G [00:46<00:29, 44.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  49%|█████████▎         | 1.26G/2.56G [00:47<00:28, 46.4MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  49%|█████████▍         | 1.27G/2.56G [00:47<00:28, 45.6MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  50%|█████████▍         | 1.28G/2.56G [00:47<00:28, 44.7MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  50%|█████████▌         | 1.29G/2.56G [00:47<00:29, 43.4MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  51%|█████████▋         | 1.30G/2.56G [00:48<00:29, 42.9MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  51%|█████████▋         | 1.31G/2.56G [00:48<00:31, 39.8MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  52%|█████████▊         | 1.32G/2.56G [00:48<00:35, 35.2MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  52%|█████████▊         | 1.33G/2.56G [00:49<00:34, 35.4MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  52%|█████████▉         | 1.34G/2.56G [00:49<00:31, 38.4MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  53%|██████████         | 1.35G/2.56G [00:49<00:29, 40.6MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  53%|██████████         | 1.36G/2.56G [00:49<00:29, 40.9MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  54%|██████████▏        | 1.37G/2.56G [00:50<00:31, 38.3MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  54%|██████████▎        | 1.38G/2.56G [00:50<00:28, 40.8MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  54%|██████████▎        | 1.39G/2.56G [00:50<00:28, 40.9MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  55%|██████████▍        | 1.41G/2.56G [00:51<00:36, 32.1MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  55%|██████████▍        | 1.42G/2.56G [00:51<00:30, 38.2MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  56%|██████████▌        | 1.43G/2.56G [00:51<00:28, 40.2MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  56%|██████████▋        | 1.44G/2.56G [00:51<00:28, 39.9MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  56%|██████████▋        | 1.45G/2.56G [00:51<00:27, 40.4MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  57%|██████████▊        | 1.46G/2.56G [00:52<00:26, 41.3MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  57%|██████████▉        | 1.47G/2.56G [00:52<00:29, 37.5MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  58%|██████████▉        | 1.48G/2.56G [00:52<00:29, 37.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  58%|███████████        | 1.49G/2.56G [00:53<00:28, 38.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  58%|███████████        | 1.50G/2.56G [00:53<00:27, 38.2MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  59%|███████████▏       | 1.51G/2.56G [00:53<00:25, 41.2MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  59%|███████████▎       | 1.52G/2.56G [00:53<00:23, 43.6MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  60%|███████████▎       | 1.53G/2.56G [00:54<00:23, 43.5MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  60%|███████████▍       | 1.54G/2.56G [00:54<00:25, 40.4MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  61%|███████████▍       | 1.55G/2.56G [00:54<00:29, 34.3MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  61%|███████████▌       | 1.56G/2.56G [00:54<00:26, 37.3MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  61%|███████████▋       | 1.57G/2.56G [00:55<00:25, 38.4MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  62%|███████████▋       | 1.58G/2.56G [00:55<00:35, 27.8MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  62%|███████████▊       | 1.59G/2.56G [00:56<00:32, 30.2MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  63%|███████████▉       | 1.60G/2.56G [00:56<00:28, 33.7MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  63%|███████████▉       | 1.61G/2.56G [00:56<00:25, 37.2MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  63%|████████████       | 1.63G/2.56G [00:56<00:23, 40.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  64%|████████████       | 1.64G/2.56G [00:57<00:23, 39.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  64%|████████████▏      | 1.65G/2.56G [00:57<00:20, 43.8MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  65%|████████████▎      | 1.66G/2.56G [00:57<00:22, 41.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  65%|████████████▎      | 1.67G/2.56G [00:57<00:22, 40.5MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  65%|████████████▍      | 1.68G/2.56G [00:58<00:21, 41.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  66%|████████████▌      | 1.69G/2.56G [00:58<00:23, 37.9MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  66%|████████████▌      | 1.70G/2.56G [00:58<00:20, 41.3MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  67%|████████████▋      | 1.71G/2.56G [00:58<00:20, 41.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  67%|████████████▋      | 1.72G/2.56G [00:59<00:19, 42.5MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  67%|████████████▊      | 1.73G/2.56G [00:59<00:19, 41.8MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  68%|████████████▉      | 1.74G/2.56G [00:59<00:18, 44.1MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  68%|████████████▉      | 1.75G/2.56G [00:59<00:18, 43.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  69%|█████████████      | 1.76G/2.56G [01:00<00:38, 20.7MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  69%|█████████████▏     | 1.77G/2.56G [01:01<00:45, 17.4MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  70%|█████████████▏     | 1.78G/2.56G [01:02<00:43, 17.9MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  70%|█████████████▎     | 1.79G/2.56G [01:02<00:37, 20.4MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  70%|█████████████▎     | 1.80G/2.56G [01:02<00:32, 23.6MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  71%|█████████████▍     | 1.81G/2.56G [01:03<00:27, 27.5MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  71%|█████████████▌     | 1.82G/2.56G [01:03<00:23, 31.2MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  72%|█████████████▌     | 1.84G/2.56G [01:03<00:21, 34.1MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  72%|█████████████▋     | 1.85G/2.56G [01:03<00:19, 36.8MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  72%|█████████████▊     | 1.86G/2.56G [01:04<00:18, 37.9MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  73%|█████████████▊     | 1.87G/2.56G [01:04<00:17, 40.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  73%|█████████████▉     | 1.88G/2.56G [01:04<00:17, 39.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  74%|█████████████▉     | 1.89G/2.56G [01:04<00:15, 44.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  74%|██████████████     | 1.90G/2.56G [01:04<00:14, 44.8MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  74%|██████████████▏    | 1.91G/2.56G [01:05<00:16, 40.8MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  75%|██████████████▏    | 1.92G/2.56G [01:05<00:14, 46.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  75%|██████████████▎    | 1.93G/2.56G [01:05<00:13, 47.8MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  76%|██████████████▎    | 1.94G/2.56G [01:05<00:13, 45.2MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  76%|██████████████▍    | 1.95G/2.56G [01:06<00:13, 44.7MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  76%|██████████████▌    | 1.96G/2.56G [01:06<00:12, 46.7MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  77%|██████████████▌    | 1.97G/2.56G [01:06<00:12, 47.4MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  77%|██████████████▋    | 1.98G/2.56G [01:06<00:12, 45.2MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  78%|██████████████▊    | 1.99G/2.56G [01:07<00:12, 47.5MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  78%|██████████████▊    | 2.00G/2.56G [01:07<00:12, 43.2MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  79%|██████████████▉    | 2.01G/2.56G [01:07<00:12, 44.4MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  79%|██████████████▉    | 2.02G/2.56G [01:07<00:11, 45.1MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  79%|███████████████    | 2.03G/2.56G [01:08<00:12, 43.8MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  80%|███████████████▏   | 2.04G/2.56G [01:08<00:11, 45.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  80%|███████████████▏   | 2.06G/2.56G [01:08<00:11, 44.4MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  81%|███████████████▎   | 2.07G/2.56G [01:08<00:10, 46.6MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  81%|███████████████▍   | 2.08G/2.56G [01:08<00:09, 49.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  81%|███████████████▍   | 2.09G/2.56G [01:09<00:10, 46.7MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  82%|███████████████▌   | 2.10G/2.56G [01:09<00:10, 43.8MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  82%|███████████████▌   | 2.11G/2.56G [01:09<00:10, 44.6MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  83%|███████████████▋   | 2.12G/2.56G [01:09<00:09, 46.4MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  83%|███████████████▊   | 2.13G/2.56G [01:10<00:09, 44.7MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  83%|███████████████▊   | 2.14G/2.56G [01:10<00:10, 42.3MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  84%|███████████████▉   | 2.15G/2.56G [01:11<00:20, 20.4MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  84%|████████████████   | 2.16G/2.56G [01:11<00:15, 25.4MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  85%|████████████████   | 2.17G/2.56G [01:11<00:13, 28.4MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  85%|████████████████▏  | 2.18G/2.56G [01:12<00:13, 28.2MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  85%|████████████████▏  | 2.19G/2.56G [01:12<00:13, 27.5MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  86%|████████████████▎  | 2.20G/2.56G [01:13<00:13, 26.8MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  86%|████████████████▍  | 2.21G/2.56G [01:13<00:11, 30.1MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  87%|████████████████▍  | 2.22G/2.56G [01:13<00:11, 29.1MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  87%|████████████████▌  | 2.23G/2.56G [01:14<00:11, 29.8MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  87%|████████████████▌  | 2.24G/2.56G [01:14<00:11, 29.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  88%|████████████████▋  | 2.25G/2.56G [01:14<00:10, 29.3MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  88%|████████████████▊  | 2.26G/2.56G [01:15<00:10, 28.7MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  89%|████████████████▊  | 2.28G/2.56G [01:15<00:10, 28.6MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  89%|████████████████▉  | 2.29G/2.56G [01:15<00:09, 29.3MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  90%|█████████████████  | 2.30G/2.56G [01:16<00:09, 28.9MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  90%|█████████████████  | 2.31G/2.56G [01:16<00:08, 29.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  90%|█████████████████▏ | 2.32G/2.56G [01:17<00:08, 28.5MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  91%|█████████████████▏ | 2.33G/2.56G [01:17<00:08, 29.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  91%|█████████████████▎ | 2.34G/2.56G [01:17<00:08, 28.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  92%|█████████████████▍ | 2.35G/2.56G [01:18<00:07, 29.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  92%|█████████████████▍ | 2.36G/2.56G [01:18<00:07, 29.2MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  92%|█████████████████▌ | 2.37G/2.56G [01:18<00:06, 28.6MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  93%|█████████████████▋ | 2.38G/2.56G [01:19<00:06, 29.2MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  93%|█████████████████▋ | 2.39G/2.56G [01:19<00:05, 29.1MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  94%|█████████████████▊ | 2.40G/2.56G [01:19<00:05, 28.5MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  94%|█████████████████▊ | 2.41G/2.56G [01:20<00:05, 28.2MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  94%|█████████████████▉ | 2.42G/2.56G [01:20<00:04, 29.6MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  95%|██████████████████ | 2.43G/2.56G [01:21<00:04, 28.8MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  95%|██████████████████ | 2.44G/2.56G [01:21<00:04, 29.1MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  96%|██████████████████▏| 2.45G/2.56G [01:21<00:03, 29.2MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  96%|██████████████████▎| 2.46G/2.56G [01:22<00:03, 29.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  96%|██████████████████▎| 2.47G/2.56G [01:22<00:03, 28.8MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  97%|██████████████████▍| 2.49G/2.56G [01:22<00:02, 27.0MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  97%|██████████████████▍| 2.50G/2.56G [01:23<00:02, 27.1MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  98%|██████████████████▌| 2.51G/2.56G [01:23<00:02, 27.7MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  98%|██████████████████▋| 2.52G/2.56G [01:24<00:01, 28.1MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  99%|██████████████████▋| 2.53G/2.56G [01:24<00:01, 27.9MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  99%|██████████████████▊| 2.54G/2.56G [01:24<00:01, 25.1MB/s]\u001b[A\r\n",
      "pytorch_model.bin:  99%|██████████████████▉| 2.55G/2.56G [01:25<00:00, 27.4MB/s]\u001b[A\r\n",
      "pytorch_model.bin: 100%|██████████████████▉| 2.56G/2.56G [01:25<00:00, 27.5MB/s]\u001b[A\r\n",
      "pytorch_model.bin: 100%|███████████████████| 2.56G/2.56G [01:25<00:00, 29.9MB/s]\r\n",
      "Download complete. Moving file to sam-vit-huge/pytorch_model.bin\r\n",
      "Fetching 5 files: 100%|███████████████████████████| 5/5 [01:27<00:00, 17.42s/it]\r\n",
      "/kaggle/working/USIS10K/pretrain/sam-vit-huge\r\n"
     ]
    }
   ],
   "source": [
    "# Make sure you're in the pretrain directory\n",
    "%cd /kaggle/working/USIS10K/pretrain\n",
    "\n",
    "# Make the script executable\n",
    "!chmod +x download_huggingface.sh\n",
    "\n",
    "# Run the script with the two arguments\n",
    "!bash download_huggingface.sh facebook/sam-vit-huge sam-vit-huge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3e02171",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T00:13:40.845701Z",
     "iopub.status.busy": "2025-11-30T00:13:40.845046Z",
     "iopub.status.idle": "2025-11-30T00:13:41.165013Z",
     "shell.execute_reply": "2025-11-30T00:13:41.164263Z"
    },
    "papermill": {
     "duration": 0.387782,
     "end_time": "2025-11-30T00:13:41.166489",
     "exception": false,
     "start_time": "2025-11-30T00:13:40.778707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/USIS10K/project/our/configs/foreground_usis_train_patched.py:        hf_pretrain_name='./pretrain/sam-vit-huge',\r\n",
      "/kaggle/working/USIS10K/project/our/configs/foreground_usis_train_patched.py:            checkpoint='./pretrain/sam-vit-huge/pytorch_model.bin',\r\n",
      "/kaggle/working/USIS10K/project/our/configs/foreground_usis_train_patched.py:                hf_pretrain_name='./pretrain/sam-vit-huge',\r\n",
      "/kaggle/working/USIS10K/project/our/configs/foreground_usis_train_patched.py:                    './pretrain/sam-vit-huge/pytorch_model.bin',\r\n",
      "/kaggle/working/USIS10K/project/our/configs/foreground_usis_train_patched.py:        hf_pretrain_name='./pretrain/sam-vit-huge',\r\n",
      "/kaggle/working/USIS10K/project/our/configs/foreground_usis_train_patched.py:            checkpoint='./pretrain/sam-vit-huge/pytorch_model.bin',\r\n",
      "/kaggle/working/USIS10K/project/our/configs/foreground_usis_train_patched.py:sam_pretrain_ckpt_path = './pretrain/sam-vit-huge/pytorch_model.bin'\r\n",
      "/kaggle/working/USIS10K/project/our/configs/foreground_usis_train_patched.py:sam_pretrain_name = './pretrain/sam-vit-huge'\r\n",
      "/kaggle/working/USIS10K/project/our/configs/anchor_net.py:sam_pretrain_name = \"./pretrain/sam-vit-huge\"\r\n",
      "/kaggle/working/USIS10K/project/our/configs/anchor_net.py:sam_pretrain_ckpt_path = \"./pretrain/sam-vit-huge/pytorch_model.bin\"\r\n"
     ]
    }
   ],
   "source": [
    "# Replace the hardcoded path in all config files\n",
    "!cd /kaggle/working/USIS10K && \\\n",
    " find ./project/our/configs -name \"*.py\" -exec sed -i 's|/root/code/pretrain/sam-vit-huge|./pretrain/sam-vit-huge|g' {} +\n",
    "\n",
    "# Verify the change\n",
    "!grep -r \"pretrain/sam-vit-huge\" /kaggle/working/USIS10K/project/our/configs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91860356",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T00:13:41.300646Z",
     "iopub.status.busy": "2025-11-30T00:13:41.299849Z",
     "iopub.status.idle": "2025-11-30T00:13:41.306698Z",
     "shell.execute_reply": "2025-11-30T00:13:41.306046Z"
    },
    "papermill": {
     "duration": 0.075493,
     "end_time": "2025-11-30T00:13:41.307720",
     "exception": false,
     "start_time": "2025-11-30T00:13:41.232227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /kaggle/working/USIS10K/vis_infer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/USIS10K/vis_infer.py\n",
    "import argparse\n",
    "from mmdet.apis import DetInferencer\n",
    "\n",
    "def vis_infer(config, checkpoints, img, output_dir):\n",
    "    \"\"\"\n",
    "    Runs the DetInferencer with user-supplied arguments.\n",
    "    \"\"\"\n",
    "    print(\"Using config:\", config)\n",
    "    print(\"Using checkpoint:\", checkpoints)\n",
    "    print(\"Using input image:\", img)\n",
    "    print(\"Saving output to:\", output_dir)\n",
    "    \n",
    "    inferencer = DetInferencer(model=config, weights=checkpoints)\n",
    "    inferencer(img, out_dir=output_dir)\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"USIS10K Visual Inference\")\n",
    "    parser.add_argument(\n",
    "        \"--config\",\n",
    "        type=str,\n",
    "        default=\"./project/our/configs/multiclass_usis_train.py\",\n",
    "        help=\"Path to config file\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--checkpoint\",\n",
    "        type=str,\n",
    "        default=\"./pretrain/multi_class_model.pth\",\n",
    "        help=\"Path to model checkpoint\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--img\",\n",
    "        type=str,\n",
    "        default=\"./data/USIS10/test/test_00001.jpg\",\n",
    "        help=\"Single input image or directory\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--out\",\n",
    "        type=str,\n",
    "        default=\"./output/\",\n",
    "        help=\"Output directory path\",\n",
    "    )\n",
    "    return parser.parse_args()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    vis_infer(\n",
    "        config=args.config,\n",
    "        checkpoints=args.checkpoint,\n",
    "        img=args.img,\n",
    "        output_dir=args.out,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3df1ec97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T00:13:41.440126Z",
     "iopub.status.busy": "2025-11-30T00:13:41.439613Z",
     "iopub.status.idle": "2025-11-30T00:13:41.889596Z",
     "shell.execute_reply": "2025-11-30T00:13:41.888946Z"
    },
    "papermill": {
     "duration": 0.517448,
     "end_time": "2025-11-30T00:13:41.890793",
     "exception": false,
     "start_time": "2025-11-30T00:13:41.373345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12d4be1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T00:13:42.025396Z",
     "iopub.status.busy": "2025-11-30T00:13:42.024749Z",
     "iopub.status.idle": "2025-11-30T00:14:19.664019Z",
     "shell.execute_reply": "2025-11-30T00:14:19.663263Z"
    },
    "papermill": {
     "duration": 37.708904,
     "end_time": "2025-11-30T00:14:19.665542",
     "exception": false,
     "start_time": "2025-11-30T00:13:41.956638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/USIS10K\n",
      "2025-11-30 00:13:45.010678: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1764461625.034331     229 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1764461625.040829     229 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\r\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\r\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\r\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\r\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\r\n",
      "Using config: ./project/our/configs/multiclass_usis_train.py\r\n",
      "Using checkpoint: ./checkpoints/multi_class_model.pth\r\n",
      "Using input image: ./data/USIS10/test/test_01423.jpg\r\n",
      "Saving output to: ./output_multiclass/\r\n",
      "Loads checkpoint by local backend from path: ./checkpoints/multi_class_model.pth\r\n",
      "Loads checkpoint by local backend from path: ./pretrain/sam-vit-huge/pytorch_model.bin\r\n",
      "The model and loaded state dict do not match exactly\r\n",
      "\r\n",
      "unexpected key in source state_dict: shared_image_embedding.positional_embedding, prompt_encoder.shared_embedding.positional_embedding, prompt_encoder.mask_embed.conv1.weight, prompt_encoder.mask_embed.conv1.bias, prompt_encoder.mask_embed.conv2.weight, prompt_encoder.mask_embed.conv2.bias, prompt_encoder.mask_embed.conv3.weight, prompt_encoder.mask_embed.conv3.bias, prompt_encoder.mask_embed.layer_norm1.weight, prompt_encoder.mask_embed.layer_norm1.bias, prompt_encoder.mask_embed.layer_norm2.weight, prompt_encoder.mask_embed.layer_norm2.bias, prompt_encoder.no_mask_embed.weight, prompt_encoder.point_embed.0.weight, prompt_encoder.point_embed.1.weight, prompt_encoder.point_embed.2.weight, prompt_encoder.point_embed.3.weight, prompt_encoder.not_a_point_embed.weight, mask_decoder.iou_token.weight, mask_decoder.mask_tokens.weight, mask_decoder.transformer.layers.0.self_attn.q_proj.weight, mask_decoder.transformer.layers.0.self_attn.q_proj.bias, mask_decoder.transformer.layers.0.self_attn.k_proj.weight, mask_decoder.transformer.layers.0.self_attn.k_proj.bias, mask_decoder.transformer.layers.0.self_attn.v_proj.weight, mask_decoder.transformer.layers.0.self_attn.v_proj.bias, mask_decoder.transformer.layers.0.self_attn.out_proj.weight, mask_decoder.transformer.layers.0.self_attn.out_proj.bias, mask_decoder.transformer.layers.0.layer_norm1.weight, mask_decoder.transformer.layers.0.layer_norm1.bias, mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.weight, mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.bias, mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.weight, mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.bias, mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.weight, mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.bias, mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.weight, mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.bias, mask_decoder.transformer.layers.0.layer_norm2.weight, mask_decoder.transformer.layers.0.layer_norm2.bias, mask_decoder.transformer.layers.0.mlp.lin1.weight, mask_decoder.transformer.layers.0.mlp.lin1.bias, mask_decoder.transformer.layers.0.mlp.lin2.weight, mask_decoder.transformer.layers.0.mlp.lin2.bias, mask_decoder.transformer.layers.0.layer_norm3.weight, mask_decoder.transformer.layers.0.layer_norm3.bias, mask_decoder.transformer.layers.0.layer_norm4.weight, mask_decoder.transformer.layers.0.layer_norm4.bias, mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.weight, mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.bias, mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.weight, mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.bias, mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.weight, mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.bias, mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.weight, mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.bias, mask_decoder.transformer.layers.1.self_attn.q_proj.weight, mask_decoder.transformer.layers.1.self_attn.q_proj.bias, mask_decoder.transformer.layers.1.self_attn.k_proj.weight, mask_decoder.transformer.layers.1.self_attn.k_proj.bias, mask_decoder.transformer.layers.1.self_attn.v_proj.weight, mask_decoder.transformer.layers.1.self_attn.v_proj.bias, mask_decoder.transformer.layers.1.self_attn.out_proj.weight, mask_decoder.transformer.layers.1.self_attn.out_proj.bias, mask_decoder.transformer.layers.1.layer_norm1.weight, mask_decoder.transformer.layers.1.layer_norm1.bias, mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.weight, mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.bias, mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.weight, mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.bias, mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.weight, mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.bias, mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.weight, mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.bias, mask_decoder.transformer.layers.1.layer_norm2.weight, mask_decoder.transformer.layers.1.layer_norm2.bias, mask_decoder.transformer.layers.1.mlp.lin1.weight, mask_decoder.transformer.layers.1.mlp.lin1.bias, mask_decoder.transformer.layers.1.mlp.lin2.weight, mask_decoder.transformer.layers.1.mlp.lin2.bias, mask_decoder.transformer.layers.1.layer_norm3.weight, mask_decoder.transformer.layers.1.layer_norm3.bias, mask_decoder.transformer.layers.1.layer_norm4.weight, mask_decoder.transformer.layers.1.layer_norm4.bias, mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.weight, mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.bias, mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.weight, mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.bias, mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.weight, mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.bias, mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.weight, mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.bias, mask_decoder.transformer.final_attn_token_to_image.q_proj.weight, mask_decoder.transformer.final_attn_token_to_image.q_proj.bias, mask_decoder.transformer.final_attn_token_to_image.k_proj.weight, mask_decoder.transformer.final_attn_token_to_image.k_proj.bias, mask_decoder.transformer.final_attn_token_to_image.v_proj.weight, mask_decoder.transformer.final_attn_token_to_image.v_proj.bias, mask_decoder.transformer.final_attn_token_to_image.out_proj.weight, mask_decoder.transformer.final_attn_token_to_image.out_proj.bias, mask_decoder.transformer.layer_norm_final_attn.weight, mask_decoder.transformer.layer_norm_final_attn.bias, mask_decoder.upscale_conv1.weight, mask_decoder.upscale_conv1.bias, mask_decoder.upscale_conv2.weight, mask_decoder.upscale_conv2.bias, mask_decoder.upscale_layer_norm.weight, mask_decoder.upscale_layer_norm.bias, mask_decoder.output_hypernetworks_mlps.0.proj_in.weight, mask_decoder.output_hypernetworks_mlps.0.proj_in.bias, mask_decoder.output_hypernetworks_mlps.0.proj_out.weight, mask_decoder.output_hypernetworks_mlps.0.proj_out.bias, mask_decoder.output_hypernetworks_mlps.0.layers.0.weight, mask_decoder.output_hypernetworks_mlps.0.layers.0.bias, mask_decoder.output_hypernetworks_mlps.1.proj_in.weight, mask_decoder.output_hypernetworks_mlps.1.proj_in.bias, mask_decoder.output_hypernetworks_mlps.1.proj_out.weight, mask_decoder.output_hypernetworks_mlps.1.proj_out.bias, mask_decoder.output_hypernetworks_mlps.1.layers.0.weight, mask_decoder.output_hypernetworks_mlps.1.layers.0.bias, mask_decoder.output_hypernetworks_mlps.2.proj_in.weight, mask_decoder.output_hypernetworks_mlps.2.proj_in.bias, mask_decoder.output_hypernetworks_mlps.2.proj_out.weight, mask_decoder.output_hypernetworks_mlps.2.proj_out.bias, mask_decoder.output_hypernetworks_mlps.2.layers.0.weight, mask_decoder.output_hypernetworks_mlps.2.layers.0.bias, mask_decoder.output_hypernetworks_mlps.3.proj_in.weight, mask_decoder.output_hypernetworks_mlps.3.proj_in.bias, mask_decoder.output_hypernetworks_mlps.3.proj_out.weight, mask_decoder.output_hypernetworks_mlps.3.proj_out.bias, mask_decoder.output_hypernetworks_mlps.3.layers.0.weight, mask_decoder.output_hypernetworks_mlps.3.layers.0.bias, mask_decoder.iou_prediction_head.proj_in.weight, mask_decoder.iou_prediction_head.proj_in.bias, mask_decoder.iou_prediction_head.proj_out.weight, mask_decoder.iou_prediction_head.proj_out.bias, mask_decoder.iou_prediction_head.layers.0.weight, mask_decoder.iou_prediction_head.layers.0.bias\r\n",
      "\r\n",
      "11/30 00:14:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: ./pretrain/sam-vit-huge/pytorch_model.bin\r\n",
      "11/30 00:14:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by local backend from path: ./pretrain/sam-vit-huge/pytorch_model.bin\r\n",
      "11/30 00:14:14 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\r\n",
      "\r\n",
      "unexpected key in source state_dict: shared_image_embedding.positional_embedding, vision_encoder.pos_embed, vision_encoder.patch_embed.projection.weight, vision_encoder.patch_embed.projection.bias, vision_encoder.layers.0.layer_norm1.weight, vision_encoder.layers.0.layer_norm1.bias, vision_encoder.layers.0.attn.rel_pos_h, vision_encoder.layers.0.attn.rel_pos_w, vision_encoder.layers.0.attn.qkv.weight, vision_encoder.layers.0.attn.qkv.bias, vision_encoder.layers.0.attn.proj.weight, vision_encoder.layers.0.attn.proj.bias, vision_encoder.layers.0.layer_norm2.weight, vision_encoder.layers.0.layer_norm2.bias, vision_encoder.layers.0.mlp.lin1.weight, vision_encoder.layers.0.mlp.lin1.bias, vision_encoder.layers.0.mlp.lin2.weight, vision_encoder.layers.0.mlp.lin2.bias, vision_encoder.layers.1.layer_norm1.weight, vision_encoder.layers.1.layer_norm1.bias, vision_encoder.layers.1.attn.rel_pos_h, vision_encoder.layers.1.attn.rel_pos_w, vision_encoder.layers.1.attn.qkv.weight, vision_encoder.layers.1.attn.qkv.bias, vision_encoder.layers.1.attn.proj.weight, vision_encoder.layers.1.attn.proj.bias, vision_encoder.layers.1.layer_norm2.weight, vision_encoder.layers.1.layer_norm2.bias, vision_encoder.layers.1.mlp.lin1.weight, vision_encoder.layers.1.mlp.lin1.bias, vision_encoder.layers.1.mlp.lin2.weight, vision_encoder.layers.1.mlp.lin2.bias, vision_encoder.layers.2.layer_norm1.weight, vision_encoder.layers.2.layer_norm1.bias, vision_encoder.layers.2.attn.rel_pos_h, vision_encoder.layers.2.attn.rel_pos_w, vision_encoder.layers.2.attn.qkv.weight, vision_encoder.layers.2.attn.qkv.bias, vision_encoder.layers.2.attn.proj.weight, vision_encoder.layers.2.attn.proj.bias, vision_encoder.layers.2.layer_norm2.weight, vision_encoder.layers.2.layer_norm2.bias, vision_encoder.layers.2.mlp.lin1.weight, vision_encoder.layers.2.mlp.lin1.bias, vision_encoder.layers.2.mlp.lin2.weight, vision_encoder.layers.2.mlp.lin2.bias, vision_encoder.layers.3.layer_norm1.weight, vision_encoder.layers.3.layer_norm1.bias, vision_encoder.layers.3.attn.rel_pos_h, vision_encoder.layers.3.attn.rel_pos_w, vision_encoder.layers.3.attn.qkv.weight, vision_encoder.layers.3.attn.qkv.bias, vision_encoder.layers.3.attn.proj.weight, vision_encoder.layers.3.attn.proj.bias, vision_encoder.layers.3.layer_norm2.weight, vision_encoder.layers.3.layer_norm2.bias, vision_encoder.layers.3.mlp.lin1.weight, vision_encoder.layers.3.mlp.lin1.bias, vision_encoder.layers.3.mlp.lin2.weight, vision_encoder.layers.3.mlp.lin2.bias, vision_encoder.layers.4.layer_norm1.weight, vision_encoder.layers.4.layer_norm1.bias, vision_encoder.layers.4.attn.rel_pos_h, vision_encoder.layers.4.attn.rel_pos_w, vision_encoder.layers.4.attn.qkv.weight, vision_encoder.layers.4.attn.qkv.bias, vision_encoder.layers.4.attn.proj.weight, vision_encoder.layers.4.attn.proj.bias, vision_encoder.layers.4.layer_norm2.weight, vision_encoder.layers.4.layer_norm2.bias, vision_encoder.layers.4.mlp.lin1.weight, vision_encoder.layers.4.mlp.lin1.bias, vision_encoder.layers.4.mlp.lin2.weight, vision_encoder.layers.4.mlp.lin2.bias, vision_encoder.layers.5.layer_norm1.weight, vision_encoder.layers.5.layer_norm1.bias, vision_encoder.layers.5.attn.rel_pos_h, vision_encoder.layers.5.attn.rel_pos_w, vision_encoder.layers.5.attn.qkv.weight, vision_encoder.layers.5.attn.qkv.bias, vision_encoder.layers.5.attn.proj.weight, vision_encoder.layers.5.attn.proj.bias, vision_encoder.layers.5.layer_norm2.weight, vision_encoder.layers.5.layer_norm2.bias, vision_encoder.layers.5.mlp.lin1.weight, vision_encoder.layers.5.mlp.lin1.bias, vision_encoder.layers.5.mlp.lin2.weight, vision_encoder.layers.5.mlp.lin2.bias, vision_encoder.layers.6.layer_norm1.weight, vision_encoder.layers.6.layer_norm1.bias, vision_encoder.layers.6.attn.rel_pos_h, vision_encoder.layers.6.attn.rel_pos_w, vision_encoder.layers.6.attn.qkv.weight, vision_encoder.layers.6.attn.qkv.bias, vision_encoder.layers.6.attn.proj.weight, vision_encoder.layers.6.attn.proj.bias, vision_encoder.layers.6.layer_norm2.weight, vision_encoder.layers.6.layer_norm2.bias, vision_encoder.layers.6.mlp.lin1.weight, vision_encoder.layers.6.mlp.lin1.bias, vision_encoder.layers.6.mlp.lin2.weight, vision_encoder.layers.6.mlp.lin2.bias, vision_encoder.layers.7.layer_norm1.weight, vision_encoder.layers.7.layer_norm1.bias, vision_encoder.layers.7.attn.rel_pos_h, vision_encoder.layers.7.attn.rel_pos_w, vision_encoder.layers.7.attn.qkv.weight, vision_encoder.layers.7.attn.qkv.bias, vision_encoder.layers.7.attn.proj.weight, vision_encoder.layers.7.attn.proj.bias, vision_encoder.layers.7.layer_norm2.weight, vision_encoder.layers.7.layer_norm2.bias, vision_encoder.layers.7.mlp.lin1.weight, vision_encoder.layers.7.mlp.lin1.bias, vision_encoder.layers.7.mlp.lin2.weight, vision_encoder.layers.7.mlp.lin2.bias, vision_encoder.layers.8.layer_norm1.weight, vision_encoder.layers.8.layer_norm1.bias, vision_encoder.layers.8.attn.rel_pos_h, vision_encoder.layers.8.attn.rel_pos_w, vision_encoder.layers.8.attn.qkv.weight, vision_encoder.layers.8.attn.qkv.bias, vision_encoder.layers.8.attn.proj.weight, vision_encoder.layers.8.attn.proj.bias, vision_encoder.layers.8.layer_norm2.weight, vision_encoder.layers.8.layer_norm2.bias, vision_encoder.layers.8.mlp.lin1.weight, vision_encoder.layers.8.mlp.lin1.bias, vision_encoder.layers.8.mlp.lin2.weight, vision_encoder.layers.8.mlp.lin2.bias, vision_encoder.layers.9.layer_norm1.weight, vision_encoder.layers.9.layer_norm1.bias, vision_encoder.layers.9.attn.rel_pos_h, vision_encoder.layers.9.attn.rel_pos_w, vision_encoder.layers.9.attn.qkv.weight, vision_encoder.layers.9.attn.qkv.bias, vision_encoder.layers.9.attn.proj.weight, vision_encoder.layers.9.attn.proj.bias, vision_encoder.layers.9.layer_norm2.weight, vision_encoder.layers.9.layer_norm2.bias, vision_encoder.layers.9.mlp.lin1.weight, vision_encoder.layers.9.mlp.lin1.bias, vision_encoder.layers.9.mlp.lin2.weight, vision_encoder.layers.9.mlp.lin2.bias, vision_encoder.layers.10.layer_norm1.weight, vision_encoder.layers.10.layer_norm1.bias, vision_encoder.layers.10.attn.rel_pos_h, vision_encoder.layers.10.attn.rel_pos_w, vision_encoder.layers.10.attn.qkv.weight, vision_encoder.layers.10.attn.qkv.bias, vision_encoder.layers.10.attn.proj.weight, vision_encoder.layers.10.attn.proj.bias, vision_encoder.layers.10.layer_norm2.weight, vision_encoder.layers.10.layer_norm2.bias, vision_encoder.layers.10.mlp.lin1.weight, vision_encoder.layers.10.mlp.lin1.bias, vision_encoder.layers.10.mlp.lin2.weight, vision_encoder.layers.10.mlp.lin2.bias, vision_encoder.layers.11.layer_norm1.weight, vision_encoder.layers.11.layer_norm1.bias, vision_encoder.layers.11.attn.rel_pos_h, vision_encoder.layers.11.attn.rel_pos_w, vision_encoder.layers.11.attn.qkv.weight, vision_encoder.layers.11.attn.qkv.bias, vision_encoder.layers.11.attn.proj.weight, vision_encoder.layers.11.attn.proj.bias, vision_encoder.layers.11.layer_norm2.weight, vision_encoder.layers.11.layer_norm2.bias, vision_encoder.layers.11.mlp.lin1.weight, vision_encoder.layers.11.mlp.lin1.bias, vision_encoder.layers.11.mlp.lin2.weight, vision_encoder.layers.11.mlp.lin2.bias, vision_encoder.layers.12.layer_norm1.weight, vision_encoder.layers.12.layer_norm1.bias, vision_encoder.layers.12.attn.rel_pos_h, vision_encoder.layers.12.attn.rel_pos_w, vision_encoder.layers.12.attn.qkv.weight, vision_encoder.layers.12.attn.qkv.bias, vision_encoder.layers.12.attn.proj.weight, vision_encoder.layers.12.attn.proj.bias, vision_encoder.layers.12.layer_norm2.weight, vision_encoder.layers.12.layer_norm2.bias, vision_encoder.layers.12.mlp.lin1.weight, vision_encoder.layers.12.mlp.lin1.bias, vision_encoder.layers.12.mlp.lin2.weight, vision_encoder.layers.12.mlp.lin2.bias, vision_encoder.layers.13.layer_norm1.weight, vision_encoder.layers.13.layer_norm1.bias, vision_encoder.layers.13.attn.rel_pos_h, vision_encoder.layers.13.attn.rel_pos_w, vision_encoder.layers.13.attn.qkv.weight, vision_encoder.layers.13.attn.qkv.bias, vision_encoder.layers.13.attn.proj.weight, vision_encoder.layers.13.attn.proj.bias, vision_encoder.layers.13.layer_norm2.weight, vision_encoder.layers.13.layer_norm2.bias, vision_encoder.layers.13.mlp.lin1.weight, vision_encoder.layers.13.mlp.lin1.bias, vision_encoder.layers.13.mlp.lin2.weight, vision_encoder.layers.13.mlp.lin2.bias, vision_encoder.layers.14.layer_norm1.weight, vision_encoder.layers.14.layer_norm1.bias, vision_encoder.layers.14.attn.rel_pos_h, vision_encoder.layers.14.attn.rel_pos_w, vision_encoder.layers.14.attn.qkv.weight, vision_encoder.layers.14.attn.qkv.bias, vision_encoder.layers.14.attn.proj.weight, vision_encoder.layers.14.attn.proj.bias, vision_encoder.layers.14.layer_norm2.weight, vision_encoder.layers.14.layer_norm2.bias, vision_encoder.layers.14.mlp.lin1.weight, vision_encoder.layers.14.mlp.lin1.bias, vision_encoder.layers.14.mlp.lin2.weight, vision_encoder.layers.14.mlp.lin2.bias, vision_encoder.layers.15.layer_norm1.weight, vision_encoder.layers.15.layer_norm1.bias, vision_encoder.layers.15.attn.rel_pos_h, vision_encoder.layers.15.attn.rel_pos_w, vision_encoder.layers.15.attn.qkv.weight, vision_encoder.layers.15.attn.qkv.bias, vision_encoder.layers.15.attn.proj.weight, vision_encoder.layers.15.attn.proj.bias, vision_encoder.layers.15.layer_norm2.weight, vision_encoder.layers.15.layer_norm2.bias, vision_encoder.layers.15.mlp.lin1.weight, vision_encoder.layers.15.mlp.lin1.bias, vision_encoder.layers.15.mlp.lin2.weight, vision_encoder.layers.15.mlp.lin2.bias, vision_encoder.layers.16.layer_norm1.weight, vision_encoder.layers.16.layer_norm1.bias, vision_encoder.layers.16.attn.rel_pos_h, vision_encoder.layers.16.attn.rel_pos_w, vision_encoder.layers.16.attn.qkv.weight, vision_encoder.layers.16.attn.qkv.bias, vision_encoder.layers.16.attn.proj.weight, vision_encoder.layers.16.attn.proj.bias, vision_encoder.layers.16.layer_norm2.weight, vision_encoder.layers.16.layer_norm2.bias, vision_encoder.layers.16.mlp.lin1.weight, vision_encoder.layers.16.mlp.lin1.bias, vision_encoder.layers.16.mlp.lin2.weight, vision_encoder.layers.16.mlp.lin2.bias, vision_encoder.layers.17.layer_norm1.weight, vision_encoder.layers.17.layer_norm1.bias, vision_encoder.layers.17.attn.rel_pos_h, vision_encoder.layers.17.attn.rel_pos_w, vision_encoder.layers.17.attn.qkv.weight, vision_encoder.layers.17.attn.qkv.bias, vision_encoder.layers.17.attn.proj.weight, vision_encoder.layers.17.attn.proj.bias, vision_encoder.layers.17.layer_norm2.weight, vision_encoder.layers.17.layer_norm2.bias, vision_encoder.layers.17.mlp.lin1.weight, vision_encoder.layers.17.mlp.lin1.bias, vision_encoder.layers.17.mlp.lin2.weight, vision_encoder.layers.17.mlp.lin2.bias, vision_encoder.layers.18.layer_norm1.weight, vision_encoder.layers.18.layer_norm1.bias, vision_encoder.layers.18.attn.rel_pos_h, vision_encoder.layers.18.attn.rel_pos_w, vision_encoder.layers.18.attn.qkv.weight, vision_encoder.layers.18.attn.qkv.bias, vision_encoder.layers.18.attn.proj.weight, vision_encoder.layers.18.attn.proj.bias, vision_encoder.layers.18.layer_norm2.weight, vision_encoder.layers.18.layer_norm2.bias, vision_encoder.layers.18.mlp.lin1.weight, vision_encoder.layers.18.mlp.lin1.bias, vision_encoder.layers.18.mlp.lin2.weight, vision_encoder.layers.18.mlp.lin2.bias, vision_encoder.layers.19.layer_norm1.weight, vision_encoder.layers.19.layer_norm1.bias, vision_encoder.layers.19.attn.rel_pos_h, vision_encoder.layers.19.attn.rel_pos_w, vision_encoder.layers.19.attn.qkv.weight, vision_encoder.layers.19.attn.qkv.bias, vision_encoder.layers.19.attn.proj.weight, vision_encoder.layers.19.attn.proj.bias, vision_encoder.layers.19.layer_norm2.weight, vision_encoder.layers.19.layer_norm2.bias, vision_encoder.layers.19.mlp.lin1.weight, vision_encoder.layers.19.mlp.lin1.bias, vision_encoder.layers.19.mlp.lin2.weight, vision_encoder.layers.19.mlp.lin2.bias, vision_encoder.layers.20.layer_norm1.weight, vision_encoder.layers.20.layer_norm1.bias, vision_encoder.layers.20.attn.rel_pos_h, vision_encoder.layers.20.attn.rel_pos_w, vision_encoder.layers.20.attn.qkv.weight, vision_encoder.layers.20.attn.qkv.bias, vision_encoder.layers.20.attn.proj.weight, vision_encoder.layers.20.attn.proj.bias, vision_encoder.layers.20.layer_norm2.weight, vision_encoder.layers.20.layer_norm2.bias, vision_encoder.layers.20.mlp.lin1.weight, vision_encoder.layers.20.mlp.lin1.bias, vision_encoder.layers.20.mlp.lin2.weight, vision_encoder.layers.20.mlp.lin2.bias, vision_encoder.layers.21.layer_norm1.weight, vision_encoder.layers.21.layer_norm1.bias, vision_encoder.layers.21.attn.rel_pos_h, vision_encoder.layers.21.attn.rel_pos_w, vision_encoder.layers.21.attn.qkv.weight, vision_encoder.layers.21.attn.qkv.bias, vision_encoder.layers.21.attn.proj.weight, vision_encoder.layers.21.attn.proj.bias, vision_encoder.layers.21.layer_norm2.weight, vision_encoder.layers.21.layer_norm2.bias, vision_encoder.layers.21.mlp.lin1.weight, vision_encoder.layers.21.mlp.lin1.bias, vision_encoder.layers.21.mlp.lin2.weight, vision_encoder.layers.21.mlp.lin2.bias, vision_encoder.layers.22.layer_norm1.weight, vision_encoder.layers.22.layer_norm1.bias, vision_encoder.layers.22.attn.rel_pos_h, vision_encoder.layers.22.attn.rel_pos_w, vision_encoder.layers.22.attn.qkv.weight, vision_encoder.layers.22.attn.qkv.bias, vision_encoder.layers.22.attn.proj.weight, vision_encoder.layers.22.attn.proj.bias, vision_encoder.layers.22.layer_norm2.weight, vision_encoder.layers.22.layer_norm2.bias, vision_encoder.layers.22.mlp.lin1.weight, vision_encoder.layers.22.mlp.lin1.bias, vision_encoder.layers.22.mlp.lin2.weight, vision_encoder.layers.22.mlp.lin2.bias, vision_encoder.layers.23.layer_norm1.weight, vision_encoder.layers.23.layer_norm1.bias, vision_encoder.layers.23.attn.rel_pos_h, vision_encoder.layers.23.attn.rel_pos_w, vision_encoder.layers.23.attn.qkv.weight, vision_encoder.layers.23.attn.qkv.bias, vision_encoder.layers.23.attn.proj.weight, vision_encoder.layers.23.attn.proj.bias, vision_encoder.layers.23.layer_norm2.weight, vision_encoder.layers.23.layer_norm2.bias, vision_encoder.layers.23.mlp.lin1.weight, vision_encoder.layers.23.mlp.lin1.bias, vision_encoder.layers.23.mlp.lin2.weight, vision_encoder.layers.23.mlp.lin2.bias, vision_encoder.layers.24.layer_norm1.weight, vision_encoder.layers.24.layer_norm1.bias, vision_encoder.layers.24.attn.rel_pos_h, vision_encoder.layers.24.attn.rel_pos_w, vision_encoder.layers.24.attn.qkv.weight, vision_encoder.layers.24.attn.qkv.bias, vision_encoder.layers.24.attn.proj.weight, vision_encoder.layers.24.attn.proj.bias, vision_encoder.layers.24.layer_norm2.weight, vision_encoder.layers.24.layer_norm2.bias, vision_encoder.layers.24.mlp.lin1.weight, vision_encoder.layers.24.mlp.lin1.bias, vision_encoder.layers.24.mlp.lin2.weight, vision_encoder.layers.24.mlp.lin2.bias, vision_encoder.layers.25.layer_norm1.weight, vision_encoder.layers.25.layer_norm1.bias, vision_encoder.layers.25.attn.rel_pos_h, vision_encoder.layers.25.attn.rel_pos_w, vision_encoder.layers.25.attn.qkv.weight, vision_encoder.layers.25.attn.qkv.bias, vision_encoder.layers.25.attn.proj.weight, vision_encoder.layers.25.attn.proj.bias, vision_encoder.layers.25.layer_norm2.weight, vision_encoder.layers.25.layer_norm2.bias, vision_encoder.layers.25.mlp.lin1.weight, vision_encoder.layers.25.mlp.lin1.bias, vision_encoder.layers.25.mlp.lin2.weight, vision_encoder.layers.25.mlp.lin2.bias, vision_encoder.layers.26.layer_norm1.weight, vision_encoder.layers.26.layer_norm1.bias, vision_encoder.layers.26.attn.rel_pos_h, vision_encoder.layers.26.attn.rel_pos_w, vision_encoder.layers.26.attn.qkv.weight, vision_encoder.layers.26.attn.qkv.bias, vision_encoder.layers.26.attn.proj.weight, vision_encoder.layers.26.attn.proj.bias, vision_encoder.layers.26.layer_norm2.weight, vision_encoder.layers.26.layer_norm2.bias, vision_encoder.layers.26.mlp.lin1.weight, vision_encoder.layers.26.mlp.lin1.bias, vision_encoder.layers.26.mlp.lin2.weight, vision_encoder.layers.26.mlp.lin2.bias, vision_encoder.layers.27.layer_norm1.weight, vision_encoder.layers.27.layer_norm1.bias, vision_encoder.layers.27.attn.rel_pos_h, vision_encoder.layers.27.attn.rel_pos_w, vision_encoder.layers.27.attn.qkv.weight, vision_encoder.layers.27.attn.qkv.bias, vision_encoder.layers.27.attn.proj.weight, vision_encoder.layers.27.attn.proj.bias, vision_encoder.layers.27.layer_norm2.weight, vision_encoder.layers.27.layer_norm2.bias, vision_encoder.layers.27.mlp.lin1.weight, vision_encoder.layers.27.mlp.lin1.bias, vision_encoder.layers.27.mlp.lin2.weight, vision_encoder.layers.27.mlp.lin2.bias, vision_encoder.layers.28.layer_norm1.weight, vision_encoder.layers.28.layer_norm1.bias, vision_encoder.layers.28.attn.rel_pos_h, vision_encoder.layers.28.attn.rel_pos_w, vision_encoder.layers.28.attn.qkv.weight, vision_encoder.layers.28.attn.qkv.bias, vision_encoder.layers.28.attn.proj.weight, vision_encoder.layers.28.attn.proj.bias, vision_encoder.layers.28.layer_norm2.weight, vision_encoder.layers.28.layer_norm2.bias, vision_encoder.layers.28.mlp.lin1.weight, vision_encoder.layers.28.mlp.lin1.bias, vision_encoder.layers.28.mlp.lin2.weight, vision_encoder.layers.28.mlp.lin2.bias, vision_encoder.layers.29.layer_norm1.weight, vision_encoder.layers.29.layer_norm1.bias, vision_encoder.layers.29.attn.rel_pos_h, vision_encoder.layers.29.attn.rel_pos_w, vision_encoder.layers.29.attn.qkv.weight, vision_encoder.layers.29.attn.qkv.bias, vision_encoder.layers.29.attn.proj.weight, vision_encoder.layers.29.attn.proj.bias, vision_encoder.layers.29.layer_norm2.weight, vision_encoder.layers.29.layer_norm2.bias, vision_encoder.layers.29.mlp.lin1.weight, vision_encoder.layers.29.mlp.lin1.bias, vision_encoder.layers.29.mlp.lin2.weight, vision_encoder.layers.29.mlp.lin2.bias, vision_encoder.layers.30.layer_norm1.weight, vision_encoder.layers.30.layer_norm1.bias, vision_encoder.layers.30.attn.rel_pos_h, vision_encoder.layers.30.attn.rel_pos_w, vision_encoder.layers.30.attn.qkv.weight, vision_encoder.layers.30.attn.qkv.bias, vision_encoder.layers.30.attn.proj.weight, vision_encoder.layers.30.attn.proj.bias, vision_encoder.layers.30.layer_norm2.weight, vision_encoder.layers.30.layer_norm2.bias, vision_encoder.layers.30.mlp.lin1.weight, vision_encoder.layers.30.mlp.lin1.bias, vision_encoder.layers.30.mlp.lin2.weight, vision_encoder.layers.30.mlp.lin2.bias, vision_encoder.layers.31.layer_norm1.weight, vision_encoder.layers.31.layer_norm1.bias, vision_encoder.layers.31.attn.rel_pos_h, vision_encoder.layers.31.attn.rel_pos_w, vision_encoder.layers.31.attn.qkv.weight, vision_encoder.layers.31.attn.qkv.bias, vision_encoder.layers.31.attn.proj.weight, vision_encoder.layers.31.attn.proj.bias, vision_encoder.layers.31.layer_norm2.weight, vision_encoder.layers.31.layer_norm2.bias, vision_encoder.layers.31.mlp.lin1.weight, vision_encoder.layers.31.mlp.lin1.bias, vision_encoder.layers.31.mlp.lin2.weight, vision_encoder.layers.31.mlp.lin2.bias, vision_encoder.neck.conv1.weight, vision_encoder.neck.layer_norm1.weight, vision_encoder.neck.layer_norm1.bias, vision_encoder.neck.conv2.weight, vision_encoder.neck.layer_norm2.weight, vision_encoder.neck.layer_norm2.bias, mask_decoder.iou_token.weight, mask_decoder.mask_tokens.weight, mask_decoder.transformer.layers.0.self_attn.q_proj.weight, mask_decoder.transformer.layers.0.self_attn.q_proj.bias, mask_decoder.transformer.layers.0.self_attn.k_proj.weight, mask_decoder.transformer.layers.0.self_attn.k_proj.bias, mask_decoder.transformer.layers.0.self_attn.v_proj.weight, mask_decoder.transformer.layers.0.self_attn.v_proj.bias, mask_decoder.transformer.layers.0.self_attn.out_proj.weight, mask_decoder.transformer.layers.0.self_attn.out_proj.bias, mask_decoder.transformer.layers.0.layer_norm1.weight, mask_decoder.transformer.layers.0.layer_norm1.bias, mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.weight, mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.bias, mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.weight, mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.bias, mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.weight, mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.bias, mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.weight, mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.bias, mask_decoder.transformer.layers.0.layer_norm2.weight, mask_decoder.transformer.layers.0.layer_norm2.bias, mask_decoder.transformer.layers.0.mlp.lin1.weight, mask_decoder.transformer.layers.0.mlp.lin1.bias, mask_decoder.transformer.layers.0.mlp.lin2.weight, mask_decoder.transformer.layers.0.mlp.lin2.bias, mask_decoder.transformer.layers.0.layer_norm3.weight, mask_decoder.transformer.layers.0.layer_norm3.bias, mask_decoder.transformer.layers.0.layer_norm4.weight, mask_decoder.transformer.layers.0.layer_norm4.bias, mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.weight, mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.bias, mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.weight, mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.bias, mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.weight, mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.bias, mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.weight, mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.bias, mask_decoder.transformer.layers.1.self_attn.q_proj.weight, mask_decoder.transformer.layers.1.self_attn.q_proj.bias, mask_decoder.transformer.layers.1.self_attn.k_proj.weight, mask_decoder.transformer.layers.1.self_attn.k_proj.bias, mask_decoder.transformer.layers.1.self_attn.v_proj.weight, mask_decoder.transformer.layers.1.self_attn.v_proj.bias, mask_decoder.transformer.layers.1.self_attn.out_proj.weight, mask_decoder.transformer.layers.1.self_attn.out_proj.bias, mask_decoder.transformer.layers.1.layer_norm1.weight, mask_decoder.transformer.layers.1.layer_norm1.bias, mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.weight, mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.bias, mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.weight, mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.bias, mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.weight, mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.bias, mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.weight, mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.bias, mask_decoder.transformer.layers.1.layer_norm2.weight, mask_decoder.transformer.layers.1.layer_norm2.bias, mask_decoder.transformer.layers.1.mlp.lin1.weight, mask_decoder.transformer.layers.1.mlp.lin1.bias, mask_decoder.transformer.layers.1.mlp.lin2.weight, mask_decoder.transformer.layers.1.mlp.lin2.bias, mask_decoder.transformer.layers.1.layer_norm3.weight, mask_decoder.transformer.layers.1.layer_norm3.bias, mask_decoder.transformer.layers.1.layer_norm4.weight, mask_decoder.transformer.layers.1.layer_norm4.bias, mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.weight, mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.bias, mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.weight, mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.bias, mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.weight, mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.bias, mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.weight, mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.bias, mask_decoder.transformer.final_attn_token_to_image.q_proj.weight, mask_decoder.transformer.final_attn_token_to_image.q_proj.bias, mask_decoder.transformer.final_attn_token_to_image.k_proj.weight, mask_decoder.transformer.final_attn_token_to_image.k_proj.bias, mask_decoder.transformer.final_attn_token_to_image.v_proj.weight, mask_decoder.transformer.final_attn_token_to_image.v_proj.bias, mask_decoder.transformer.final_attn_token_to_image.out_proj.weight, mask_decoder.transformer.final_attn_token_to_image.out_proj.bias, mask_decoder.transformer.layer_norm_final_attn.weight, mask_decoder.transformer.layer_norm_final_attn.bias, mask_decoder.upscale_conv1.weight, mask_decoder.upscale_conv1.bias, mask_decoder.upscale_conv2.weight, mask_decoder.upscale_conv2.bias, mask_decoder.upscale_layer_norm.weight, mask_decoder.upscale_layer_norm.bias, mask_decoder.output_hypernetworks_mlps.0.proj_in.weight, mask_decoder.output_hypernetworks_mlps.0.proj_in.bias, mask_decoder.output_hypernetworks_mlps.0.proj_out.weight, mask_decoder.output_hypernetworks_mlps.0.proj_out.bias, mask_decoder.output_hypernetworks_mlps.0.layers.0.weight, mask_decoder.output_hypernetworks_mlps.0.layers.0.bias, mask_decoder.output_hypernetworks_mlps.1.proj_in.weight, mask_decoder.output_hypernetworks_mlps.1.proj_in.bias, mask_decoder.output_hypernetworks_mlps.1.proj_out.weight, mask_decoder.output_hypernetworks_mlps.1.proj_out.bias, mask_decoder.output_hypernetworks_mlps.1.layers.0.weight, mask_decoder.output_hypernetworks_mlps.1.layers.0.bias, mask_decoder.output_hypernetworks_mlps.2.proj_in.weight, mask_decoder.output_hypernetworks_mlps.2.proj_in.bias, mask_decoder.output_hypernetworks_mlps.2.proj_out.weight, mask_decoder.output_hypernetworks_mlps.2.proj_out.bias, mask_decoder.output_hypernetworks_mlps.2.layers.0.weight, mask_decoder.output_hypernetworks_mlps.2.layers.0.bias, mask_decoder.output_hypernetworks_mlps.3.proj_in.weight, mask_decoder.output_hypernetworks_mlps.3.proj_in.bias, mask_decoder.output_hypernetworks_mlps.3.proj_out.weight, mask_decoder.output_hypernetworks_mlps.3.proj_out.bias, mask_decoder.output_hypernetworks_mlps.3.layers.0.weight, mask_decoder.output_hypernetworks_mlps.3.layers.0.bias, mask_decoder.iou_prediction_head.proj_in.weight, mask_decoder.iou_prediction_head.proj_in.bias, mask_decoder.iou_prediction_head.proj_out.weight, mask_decoder.iou_prediction_head.proj_out.bias, mask_decoder.iou_prediction_head.layers.0.weight, mask_decoder.iou_prediction_head.layers.0.bias, prompt_encoder.shared_embedding.positional_embedding\r\n",
      "\r\n",
      "11/30 00:14:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \r\n",
      "prompt_encoder.mask_embed.conv1.weight - torch.Size([4, 1, 2, 2]): \r\n",
      "PretrainedInit: load from ./pretrain/sam-vit-huge/pytorch_model.bin \r\n",
      " \r\n",
      "11/30 00:14:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \r\n",
      "prompt_encoder.mask_embed.conv1.bias - torch.Size([4]): \r\n",
      "PretrainedInit: load from ./pretrain/sam-vit-huge/pytorch_model.bin \r\n",
      " \r\n",
      "11/30 00:14:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \r\n",
      "prompt_encoder.mask_embed.conv2.weight - torch.Size([16, 4, 2, 2]): \r\n",
      "PretrainedInit: load from ./pretrain/sam-vit-huge/pytorch_model.bin \r\n",
      " \r\n",
      "11/30 00:14:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \r\n",
      "prompt_encoder.mask_embed.conv2.bias - torch.Size([16]): \r\n",
      "PretrainedInit: load from ./pretrain/sam-vit-huge/pytorch_model.bin \r\n",
      " \r\n",
      "11/30 00:14:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \r\n",
      "prompt_encoder.mask_embed.conv3.weight - torch.Size([256, 16, 1, 1]): \r\n",
      "PretrainedInit: load from ./pretrain/sam-vit-huge/pytorch_model.bin \r\n",
      " \r\n",
      "11/30 00:14:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \r\n",
      "prompt_encoder.mask_embed.conv3.bias - torch.Size([256]): \r\n",
      "PretrainedInit: load from ./pretrain/sam-vit-huge/pytorch_model.bin \r\n",
      " \r\n",
      "11/30 00:14:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \r\n",
      "prompt_encoder.mask_embed.layer_norm1.weight - torch.Size([4]): \r\n",
      "PretrainedInit: load from ./pretrain/sam-vit-huge/pytorch_model.bin \r\n",
      " \r\n",
      "11/30 00:14:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \r\n",
      "prompt_encoder.mask_embed.layer_norm1.bias - torch.Size([4]): \r\n",
      "PretrainedInit: load from ./pretrain/sam-vit-huge/pytorch_model.bin \r\n",
      " \r\n",
      "11/30 00:14:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \r\n",
      "prompt_encoder.mask_embed.layer_norm2.weight - torch.Size([16]): \r\n",
      "PretrainedInit: load from ./pretrain/sam-vit-huge/pytorch_model.bin \r\n",
      " \r\n",
      "11/30 00:14:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \r\n",
      "prompt_encoder.mask_embed.layer_norm2.bias - torch.Size([16]): \r\n",
      "PretrainedInit: load from ./pretrain/sam-vit-huge/pytorch_model.bin \r\n",
      " \r\n",
      "11/30 00:14:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \r\n",
      "prompt_encoder.no_mask_embed.weight - torch.Size([1, 256]): \r\n",
      "PretrainedInit: load from ./pretrain/sam-vit-huge/pytorch_model.bin \r\n",
      " \r\n",
      "11/30 00:14:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \r\n",
      "prompt_encoder.point_embed.0.weight - torch.Size([1, 256]): \r\n",
      "PretrainedInit: load from ./pretrain/sam-vit-huge/pytorch_model.bin \r\n",
      " \r\n",
      "11/30 00:14:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \r\n",
      "prompt_encoder.point_embed.1.weight - torch.Size([1, 256]): \r\n",
      "PretrainedInit: load from ./pretrain/sam-vit-huge/pytorch_model.bin \r\n",
      " \r\n",
      "11/30 00:14:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \r\n",
      "prompt_encoder.point_embed.2.weight - torch.Size([1, 256]): \r\n",
      "PretrainedInit: load from ./pretrain/sam-vit-huge/pytorch_model.bin \r\n",
      " \r\n",
      "11/30 00:14:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \r\n",
      "prompt_encoder.point_embed.3.weight - torch.Size([1, 256]): \r\n",
      "PretrainedInit: load from ./pretrain/sam-vit-huge/pytorch_model.bin \r\n",
      " \r\n",
      "11/30 00:14:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \r\n",
      "prompt_encoder.not_a_point_embed.weight - torch.Size([1, 256]): \r\n",
      "PretrainedInit: load from ./pretrain/sam-vit-huge/pytorch_model.bin \r\n",
      " \r\n",
      "11/30 00:14:15 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmdet\" in the \"function\" registry tree. As a workaround, the current \"function\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmdet\" is a correct scope, or whether the registry is initialized.\r\n",
      "/usr/local/lib/python3.11/dist-packages/mmengine/visualization/visualizer.py:196: UserWarning: Failed to add <class 'mmengine.visualization.vis_backend.LocalVisBackend'>, please provide the `save_dir` argument.\r\n",
      "  warnings.warn(f'Failed to add {vis_backend.__class__}, '\r\n",
      "\u001b[2KInference \u001b[35m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[35m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[35m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[35m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m  \u001b[36m \u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/USIS10K\n",
    "!python vis_infer.py \\\n",
    "    --config ./project/our/configs/multiclass_usis_train.py \\\n",
    "    --checkpoint ./checkpoints/multi_class_model.pth \\\n",
    "    --img ./data/USIS10/test/test_01423.jpg \\\n",
    "    --out ./output_multiclass/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ddef28b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T00:14:19.807183Z",
     "iopub.status.busy": "2025-11-30T00:14:19.806518Z",
     "iopub.status.idle": "2025-11-30T00:14:19.813567Z",
     "shell.execute_reply": "2025-11-30T00:14:19.812899Z"
    },
    "papermill": {
     "duration": 0.078315,
     "end_time": "2025-11-30T00:14:19.814661",
     "exception": false,
     "start_time": "2025-11-30T00:14:19.736346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking multi-class output directory:\n",
      "/kaggle/working/USIS10K/output_multiclass/\n",
      "✅ Found 1 files:\n",
      "['vis']\n",
      "Skipping non-image file: vis\n"
     ]
    }
   ],
   "source": [
    "# === Multi-Class Inference Output Viewer ===\n",
    "\n",
    "import os\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# MODIFY THIS TO YOUR MULTI-CLASS OUTPUT FOLDER\n",
    "output_dir = \"/kaggle/working/USIS10K/output_multiclass/\"\n",
    "\n",
    "print(\"Checking multi-class output directory:\")\n",
    "print(output_dir)\n",
    "\n",
    "# Check folder exists\n",
    "if not os.path.exists(output_dir):\n",
    "    print(\"❌ Output directory does not exist! Maybe inference is still running?\")\n",
    "else:\n",
    "    files = os.listdir(output_dir)\n",
    "    if not files:\n",
    "        print(\"⚠️ Directory exists but is empty.\")\n",
    "    else:\n",
    "        print(f\"✅ Found {len(files)} files:\")\n",
    "        print(files)\n",
    "\n",
    "        # Display images\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                print(f\"\\nDisplaying: {file}\")\n",
    "                display(Image(filename=os.path.join(output_dir, file)))\n",
    "            else:\n",
    "                print(f\"Skipping non-image file: {file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d4474c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T00:14:19.953145Z",
     "iopub.status.busy": "2025-11-30T00:14:19.952864Z",
     "iopub.status.idle": "2025-11-30T00:14:20.103871Z",
     "shell.execute_reply": "2025-11-30T00:14:20.102977Z"
    },
    "papermill": {
     "duration": 0.221801,
     "end_time": "2025-11-30T00:14:20.104982",
     "exception": false,
     "start_time": "2025-11-30T00:14:19.883181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/kaggle/working/USIS10K/output/vis/': No such file or directory\r\n",
      "Vis directory not found\n"
     ]
    }
   ],
   "source": [
    "# Check what's inside the vis directory\n",
    "!ls -la /kaggle/working/USIS10K/output/vis/\n",
    "\n",
    "# Display the results\n",
    "from IPython.display import Image, display\n",
    "import os\n",
    "\n",
    "vis_dir = \"/kaggle/working/USIS10K/output/vis/\"\n",
    "if os.path.exists(vis_dir):\n",
    "    files = os.listdir(vis_dir)\n",
    "    print(\"Result files:\", files)\n",
    "    \n",
    "    for file in sorted(files):\n",
    "        if file.endswith(('.jpg', '.png', '.jpeg')):\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Displaying: {file}\")\n",
    "            print('='*50)\n",
    "            display(Image(filename=os.path.join(vis_dir, file)))\n",
    "else:\n",
    "    print(\"Vis directory not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06031a74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T00:14:20.244633Z",
     "iopub.status.busy": "2025-11-30T00:14:20.244064Z",
     "iopub.status.idle": "2025-11-30T00:14:20.249092Z",
     "shell.execute_reply": "2025-11-30T00:14:20.248393Z"
    },
    "papermill": {
     "duration": 0.076302,
     "end_time": "2025-11-30T00:14:20.250087",
     "exception": false,
     "start_time": "2025-11-30T00:14:20.173785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symlink created: /kaggle/working/USIS10K/data/USIS10K → /kaggle/working/USIS10K/data/USIS10\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "src = \"/kaggle/working/USIS10K/data/USIS10\"\n",
    "dst = \"/kaggle/working/USIS10K/data/USIS10K\"\n",
    "\n",
    "if not os.path.exists(dst):\n",
    "    os.symlink(src, dst)\n",
    "\n",
    "print(\"Symlink created:\", dst, \"→\", src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0a8e458",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T00:14:20.389849Z",
     "iopub.status.busy": "2025-11-30T00:14:20.389266Z",
     "iopub.status.idle": "2025-11-30T00:14:20.535557Z",
     "shell.execute_reply": "2025-11-30T00:14:20.534703Z"
    },
    "papermill": {
     "duration": 0.218578,
     "end_time": "2025-11-30T00:14:20.536948",
     "exception": false,
     "start_time": "2025-11-30T00:14:20.318370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: /kaggle/working/USIS10k: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!cat /kaggle/working/USIS10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99634226",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T00:14:20.674462Z",
     "iopub.status.busy": "2025-11-30T00:14:20.674050Z",
     "iopub.status.idle": "2025-11-30T00:14:33.972728Z",
     "shell.execute_reply": "2025-11-30T00:14:33.971616Z"
    },
    "papermill": {
     "duration": 13.368496,
     "end_time": "2025-11-30T00:14:33.973879",
     "exception": true,
     "start_time": "2025-11-30T00:14:20.605383",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/USIS10K\n",
      "11/30 00:14:21 - mmengine - INFO - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 1490691041\n",
      "    GPU 0: Tesla P100-PCIE-16GB\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 12.5, V12.5.82\n",
      "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "    PyTorch: 2.1.2+cu118\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2025.3-Product Build 20251007 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 11.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.7\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.16.2+cu118\n",
      "    OpenCV: 4.12.0\n",
      "    MMEngine: 0.10.4\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 1490691041\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "11/30 00:14:21 - mmengine - INFO - Config:\n",
      "CLASSES = dict(classes=[\n",
      "    'wrecks/ruins',\n",
      "    'fish',\n",
      "    'reefs',\n",
      "    'aquatic plants',\n",
      "    'human divers',\n",
      "    'robots',\n",
      "    'sea-floor',\n",
      "])\n",
      "auto_scale_lr = dict(base_batch_size=2, enable=False)\n",
      "backend_args = None\n",
      "base_lr = 0.0001\n",
      "batch_augments = [\n",
      "    dict(\n",
      "        img_pad_value=0,\n",
      "        mask_pad_value=0,\n",
      "        pad_mask=True,\n",
      "        pad_seg=False,\n",
      "        size=(\n",
      "            1024,\n",
      "            1024,\n",
      "        ),\n",
      "        type='BatchFixedSizePad'),\n",
      "]\n",
      "batch_size = 2\n",
      "crop_size = (\n",
      "    1024,\n",
      "    1024,\n",
      ")\n",
      "custom_imports = dict(\n",
      "    allow_failed_imports=False, imports=[\n",
      "        'project.our.our_model',\n",
      "    ])\n",
      "data_preprocessor = dict(\n",
      "    batch_augments=[\n",
      "        dict(\n",
      "            img_pad_value=0,\n",
      "            mask_pad_value=0,\n",
      "            pad_mask=True,\n",
      "            pad_seg=False,\n",
      "            size=(\n",
      "                1024,\n",
      "                1024,\n",
      "            ),\n",
      "            type='BatchFixedSizePad'),\n",
      "    ],\n",
      "    bgr_to_rgb=True,\n",
      "    mean=[\n",
      "        123.675,\n",
      "        116.28,\n",
      "        103.53,\n",
      "    ],\n",
      "    pad_mask=True,\n",
      "    pad_size_divisor=32,\n",
      "    std=[\n",
      "        58.395,\n",
      "        57.120000000000005,\n",
      "        57.375,\n",
      "    ],\n",
      "    type='DetDataPreprocessor')\n",
      "data_root = 'data/USIS10K'\n",
      "dataset_type = 'MultiClassUSIS10KInsSegDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        interval=3,\n",
      "        max_keep_ckpts=1,\n",
      "        rule='greater',\n",
      "        save_best=[\n",
      "            'coco/bbox_mAP',\n",
      "            'coco/segm_mAP',\n",
      "        ],\n",
      "        save_last=True,\n",
      "        type='CheckpointHook'),\n",
      "    logger=dict(interval=20, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "find_unused_parameters = True\n",
      "indices = None\n",
      "load_from = 'pretrain/multi_class_model.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "max_epochs = 24\n",
      "model = dict(\n",
      "    adapter=dict(\n",
      "        adapter_layer=range(8, 33, 2), embed_dim=1280, type='UAViTAdapters'),\n",
      "    backbone=dict(\n",
      "        extra_config=dict(image_size=1024, output_hidden_states=True),\n",
      "        hf_pretrain_name='./pretrain/sam-vit-huge',\n",
      "        init_cfg=dict(\n",
      "            checkpoint='./pretrain/sam-vit-huge/pytorch_model.bin',\n",
      "            type='Pretrained'),\n",
      "        peft_config=None,\n",
      "        type='USISSamVisionEncoder'),\n",
      "    data_preprocessor=dict(\n",
      "        batch_augments=[\n",
      "            dict(\n",
      "                img_pad_value=0,\n",
      "                mask_pad_value=0,\n",
      "                pad_mask=True,\n",
      "                pad_seg=False,\n",
      "                size=(\n",
      "                    1024,\n",
      "                    1024,\n",
      "                ),\n",
      "                type='BatchFixedSizePad'),\n",
      "        ],\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_mask=True,\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.120000000000005,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    decoder_freeze=True,\n",
      "    neck=dict(\n",
      "        feature_aggregator=dict(\n",
      "            hidden_channels=32,\n",
      "            in_channels=[\n",
      "                1280,\n",
      "                1280,\n",
      "                1280,\n",
      "                1280,\n",
      "                1280,\n",
      "                1280,\n",
      "                1280,\n",
      "                1280,\n",
      "                1280,\n",
      "                1280,\n",
      "                1280,\n",
      "                1280,\n",
      "                1280,\n",
      "                1280,\n",
      "                1280,\n",
      "                1280,\n",
      "                1280,\n",
      "                1280,\n",
      "                1280,\n",
      "                1280,\n",
      "                1280,\n",
      "                1280,\n",
      "                1280,\n",
      "                1280,\n",
      "                1280,\n",
      "                1280,\n",
      "                1280,\n",
      "                1280,\n",
      "                1280,\n",
      "                1280,\n",
      "                1280,\n",
      "                1280,\n",
      "                1280,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            select_layers=range(8, 33, 2),\n",
      "            type='USISFeatureAggregator'),\n",
      "        feature_spliter=dict(\n",
      "            backbone_channel=256,\n",
      "            in_channels=[\n",
      "                64,\n",
      "                128,\n",
      "                256,\n",
      "                256,\n",
      "            ],\n",
      "            norm_cfg=dict(requires_grad=True, type='LN2d'),\n",
      "            num_outs=5,\n",
      "            out_channels=256,\n",
      "            type='USISSimpleFPNHead'),\n",
      "        type='USISFPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=dict(\n",
      "            bbox_coder=dict(\n",
      "                target_means=[\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                ],\n",
      "                target_stds=[\n",
      "                    0.1,\n",
      "                    0.1,\n",
      "                    0.2,\n",
      "                    0.2,\n",
      "                ],\n",
      "                type='DeltaXYWHBBoxCoder'),\n",
      "            fc_out_channels=1024,\n",
      "            in_channels=256,\n",
      "            loss_bbox=dict(loss_weight=1.0, type='SmoothL1Loss'),\n",
      "            loss_cls=dict(\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "            num_classes=7,\n",
      "            reg_class_agnostic=False,\n",
      "            roi_feat_size=7,\n",
      "            type='Shared2FCBBoxHead'),\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        mask_head=dict(\n",
      "            class_agnostic=True,\n",
      "            in_channels=256,\n",
      "            loss_mask=dict(\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),\n",
      "            mask_decoder=dict(\n",
      "                hf_pretrain_name='./pretrain/sam-vit-huge',\n",
      "                init_cfg=dict(\n",
      "                    checkpoint='./pretrain/sam-vit-huge/pytorch_model.bin',\n",
      "                    type='Pretrained'),\n",
      "                type='USISSamMaskDecoder'),\n",
      "            multimask_output=False,\n",
      "            per_pointset_point=5,\n",
      "            roi_feat_size=14,\n",
      "            type='USISPrompterAnchorMaskHead',\n",
      "            with_sincos=True),\n",
      "        mask_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=14, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        type='USISPrompterAnchorRoIPromptHead',\n",
      "        with_extra_pe=True),\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales=[\n",
      "                4,\n",
      "                8,\n",
      "            ],\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(loss_weight=1.0, type='SmoothL1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    shared_image_embedding=dict(\n",
      "        extra_config=dict(image_size=1024),\n",
      "        hf_pretrain_name='./pretrain/sam-vit-huge',\n",
      "        init_cfg=dict(\n",
      "            checkpoint='./pretrain/sam-vit-huge/pytorch_model.bin',\n",
      "            type='Pretrained'),\n",
      "        type='USISSamPositionalEmbedding'),\n",
      "    test_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            mask_thr_binary=0.5,\n",
      "            max_per_img=100,\n",
      "            nms=dict(iou_threshold=0.5, type='nms'),\n",
      "            score_thr=0.05),\n",
      "        rpn=dict(\n",
      "            max_per_img=1000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=1000)),\n",
      "    train_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.5,\n",
      "                neg_iou_thr=0.5,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            mask_size=(\n",
      "                1024,\n",
      "                1024,\n",
      "            ),\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=True,\n",
      "                neg_pos_ub=-1,\n",
      "                num=256,\n",
      "                pos_fraction=0.25,\n",
      "                type='RandomSampler')),\n",
      "        rpn=dict(\n",
      "            allowed_border=-1,\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.3,\n",
      "                neg_iou_thr=0.3,\n",
      "                pos_iou_thr=0.7,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=False,\n",
      "                neg_pos_ub=-1,\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                type='RandomSampler')),\n",
      "        rpn_proposal=dict(\n",
      "            max_per_img=1000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=2000)),\n",
      "    type='USISAnchor')\n",
      "num_classes = 7\n",
      "num_workers = 8\n",
      "optim_wrapper = dict(\n",
      "    dtype='float16',\n",
      "    optimizer=dict(lr=0.0001, type='AdamW', weight_decay=0.05),\n",
      "    type='AmpOptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(begin=0, by_epoch=False, end=50, start_factor=0.001, type='LinearLR'),\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=24,\n",
      "        gamma=0.1,\n",
      "        milestones=[\n",
      "            15,\n",
      "            21,\n",
      "        ],\n",
      "        type='MultiStepLR'),\n",
      "]\n",
      "persistent_workers = True\n",
      "pointset_point_num = 5\n",
      "resume = False\n",
      "sam_pretrain_ckpt_path = './pretrain/sam-vit-huge/pytorch_model.bin'\n",
      "sam_pretrain_name = './pretrain/sam-vit-huge'\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        ann_file='multi_class_annotations/multi_class_test_annotations.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='test'),\n",
      "        data_root='data/USIS10K',\n",
      "        indices=None,\n",
      "        metainfo=dict(classes=[\n",
      "            'wrecks/ruins',\n",
      "            'fish',\n",
      "            'reefs',\n",
      "            'aquatic plants',\n",
      "            'human divers',\n",
      "            'robots',\n",
      "            'sea-floor',\n",
      "        ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, to_float32=True, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1024,\n",
      "                1024,\n",
      "            ), type='Resize'),\n",
      "            dict(\n",
      "                pad_val=dict(img=(\n",
      "                    103.53,\n",
      "                    116.28,\n",
      "                    123.675,\n",
      "                ), masks=0),\n",
      "                size=(\n",
      "                    1024,\n",
      "                    1024,\n",
      "                ),\n",
      "                type='Pad'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'pad_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='MultiClassUSIS10KInsSegDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file=\n",
      "    'data/USIS10K/multi_class_annotations/multi_class_test_annotations.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric=[\n",
      "        'bbox',\n",
      "        'segm',\n",
      "    ],\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, to_float32=True, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1024,\n",
      "        1024,\n",
      "    ), type='Resize'),\n",
      "    dict(\n",
      "        pad_val=dict(img=(\n",
      "            103.53,\n",
      "            116.28,\n",
      "            123.675,\n",
      "        ), masks=0),\n",
      "        size=(\n",
      "            1024,\n",
      "            1024,\n",
      "        ),\n",
      "        type='Pad'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'pad_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=24, type='EpochBasedTrainLoop', val_interval=3)\n",
      "train_dataloader = dict(\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        ann_file='multi_class_annotations/multi_class_train_annotations.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='train'),\n",
      "        data_root='data/USIS10K',\n",
      "        indices=None,\n",
      "        metainfo=dict(classes=[\n",
      "            'wrecks/ruins',\n",
      "            'fish',\n",
      "            'reefs',\n",
      "            'aquatic plants',\n",
      "            'human divers',\n",
      "            'robots',\n",
      "            'sea-floor',\n",
      "        ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, to_float32=True, type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(\n",
      "                keep_ratio=True,\n",
      "                ratio_range=(\n",
      "                    0.1,\n",
      "                    2.0,\n",
      "                ),\n",
      "                resize_type='Resize',\n",
      "                scale=(\n",
      "                    1024,\n",
      "                    1024,\n",
      "                ),\n",
      "                type='RandomResize'),\n",
      "            dict(\n",
      "                allow_negative_crop=True,\n",
      "                crop_size=(\n",
      "                    1024,\n",
      "                    1024,\n",
      "                ),\n",
      "                crop_type='absolute',\n",
      "                recompute_bbox=True,\n",
      "                type='RandomCrop'),\n",
      "            dict(\n",
      "                by_mask=True,\n",
      "                min_gt_bbox_wh=(\n",
      "                    1e-05,\n",
      "                    1e-05,\n",
      "                ),\n",
      "                type='FilterAnnotations'),\n",
      "            dict(type='PackDetInputs'),\n",
      "        ],\n",
      "        type='MultiClassUSIS10KInsSegDataset'),\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, to_float32=True, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.1,\n",
      "            2.0,\n",
      "        ),\n",
      "        resize_type='Resize',\n",
      "        scale=(\n",
      "            1024,\n",
      "            1024,\n",
      "        ),\n",
      "        type='RandomResize'),\n",
      "    dict(\n",
      "        allow_negative_crop=True,\n",
      "        crop_size=(\n",
      "            1024,\n",
      "            1024,\n",
      "        ),\n",
      "        crop_type='absolute',\n",
      "        recompute_bbox=True,\n",
      "        type='RandomCrop'),\n",
      "    dict(\n",
      "        by_mask=True,\n",
      "        min_gt_bbox_wh=(\n",
      "            1e-05,\n",
      "            1e-05,\n",
      "        ),\n",
      "        type='FilterAnnotations'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        ann_file='multi_class_annotations/multi_class_val_annotations.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='val'),\n",
      "        data_root='data/USIS10K',\n",
      "        indices=None,\n",
      "        metainfo=dict(classes=[\n",
      "            'wrecks/ruins',\n",
      "            'fish',\n",
      "            'reefs',\n",
      "            'aquatic plants',\n",
      "            'human divers',\n",
      "            'robots',\n",
      "            'sea-floor',\n",
      "        ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, to_float32=True, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1024,\n",
      "                1024,\n",
      "            ), type='Resize'),\n",
      "            dict(\n",
      "                pad_val=dict(img=(\n",
      "                    103.53,\n",
      "                    116.28,\n",
      "                    123.675,\n",
      "                ), masks=0),\n",
      "                size=(\n",
      "                    1024,\n",
      "                    1024,\n",
      "                ),\n",
      "                type='Pad'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'pad_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='MultiClassUSIS10KInsSegDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=8,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file=\n",
      "    'data/USIS10K/multi_class_annotations/multi_class_val_annotations.json',\n",
      "    backend_args=None,\n",
      "    format_only=False,\n",
      "    metric=[\n",
      "        'bbox',\n",
      "        'segm',\n",
      "    ],\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './work_dirs/USIS10KDataset/huge'\n",
      "\n",
      "Loads checkpoint by local backend from path: ./pretrain/sam-vit-huge/pytorch_model.bin\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: shared_image_embedding.positional_embedding, prompt_encoder.shared_embedding.positional_embedding, prompt_encoder.mask_embed.conv1.weight, prompt_encoder.mask_embed.conv1.bias, prompt_encoder.mask_embed.conv2.weight, prompt_encoder.mask_embed.conv2.bias, prompt_encoder.mask_embed.conv3.weight, prompt_encoder.mask_embed.conv3.bias, prompt_encoder.mask_embed.layer_norm1.weight, prompt_encoder.mask_embed.layer_norm1.bias, prompt_encoder.mask_embed.layer_norm2.weight, prompt_encoder.mask_embed.layer_norm2.bias, prompt_encoder.no_mask_embed.weight, prompt_encoder.point_embed.0.weight, prompt_encoder.point_embed.1.weight, prompt_encoder.point_embed.2.weight, prompt_encoder.point_embed.3.weight, prompt_encoder.not_a_point_embed.weight, mask_decoder.iou_token.weight, mask_decoder.mask_tokens.weight, mask_decoder.transformer.layers.0.self_attn.q_proj.weight, mask_decoder.transformer.layers.0.self_attn.q_proj.bias, mask_decoder.transformer.layers.0.self_attn.k_proj.weight, mask_decoder.transformer.layers.0.self_attn.k_proj.bias, mask_decoder.transformer.layers.0.self_attn.v_proj.weight, mask_decoder.transformer.layers.0.self_attn.v_proj.bias, mask_decoder.transformer.layers.0.self_attn.out_proj.weight, mask_decoder.transformer.layers.0.self_attn.out_proj.bias, mask_decoder.transformer.layers.0.layer_norm1.weight, mask_decoder.transformer.layers.0.layer_norm1.bias, mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.weight, mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.bias, mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.weight, mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.bias, mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.weight, mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.bias, mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.weight, mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.bias, mask_decoder.transformer.layers.0.layer_norm2.weight, mask_decoder.transformer.layers.0.layer_norm2.bias, mask_decoder.transformer.layers.0.mlp.lin1.weight, mask_decoder.transformer.layers.0.mlp.lin1.bias, mask_decoder.transformer.layers.0.mlp.lin2.weight, mask_decoder.transformer.layers.0.mlp.lin2.bias, mask_decoder.transformer.layers.0.layer_norm3.weight, mask_decoder.transformer.layers.0.layer_norm3.bias, mask_decoder.transformer.layers.0.layer_norm4.weight, mask_decoder.transformer.layers.0.layer_norm4.bias, mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.weight, mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.bias, mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.weight, mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.bias, mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.weight, mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.bias, mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.weight, mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.bias, mask_decoder.transformer.layers.1.self_attn.q_proj.weight, mask_decoder.transformer.layers.1.self_attn.q_proj.bias, mask_decoder.transformer.layers.1.self_attn.k_proj.weight, mask_decoder.transformer.layers.1.self_attn.k_proj.bias, mask_decoder.transformer.layers.1.self_attn.v_proj.weight, mask_decoder.transformer.layers.1.self_attn.v_proj.bias, mask_decoder.transformer.layers.1.self_attn.out_proj.weight, mask_decoder.transformer.layers.1.self_attn.out_proj.bias, mask_decoder.transformer.layers.1.layer_norm1.weight, mask_decoder.transformer.layers.1.layer_norm1.bias, mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.weight, mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.bias, mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.weight, mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.bias, mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.weight, mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.bias, mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.weight, mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.bias, mask_decoder.transformer.layers.1.layer_norm2.weight, mask_decoder.transformer.layers.1.layer_norm2.bias, mask_decoder.transformer.layers.1.mlp.lin1.weight, mask_decoder.transformer.layers.1.mlp.lin1.bias, mask_decoder.transformer.layers.1.mlp.lin2.weight, mask_decoder.transformer.layers.1.mlp.lin2.bias, mask_decoder.transformer.layers.1.layer_norm3.weight, mask_decoder.transformer.layers.1.layer_norm3.bias, mask_decoder.transformer.layers.1.layer_norm4.weight, mask_decoder.transformer.layers.1.layer_norm4.bias, mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.weight, mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.bias, mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.weight, mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.bias, mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.weight, mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.bias, mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.weight, mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.bias, mask_decoder.transformer.final_attn_token_to_image.q_proj.weight, mask_decoder.transformer.final_attn_token_to_image.q_proj.bias, mask_decoder.transformer.final_attn_token_to_image.k_proj.weight, mask_decoder.transformer.final_attn_token_to_image.k_proj.bias, mask_decoder.transformer.final_attn_token_to_image.v_proj.weight, mask_decoder.transformer.final_attn_token_to_image.v_proj.bias, mask_decoder.transformer.final_attn_token_to_image.out_proj.weight, mask_decoder.transformer.final_attn_token_to_image.out_proj.bias, mask_decoder.transformer.layer_norm_final_attn.weight, mask_decoder.transformer.layer_norm_final_attn.bias, mask_decoder.upscale_conv1.weight, mask_decoder.upscale_conv1.bias, mask_decoder.upscale_conv2.weight, mask_decoder.upscale_conv2.bias, mask_decoder.upscale_layer_norm.weight, mask_decoder.upscale_layer_norm.bias, mask_decoder.output_hypernetworks_mlps.0.proj_in.weight, mask_decoder.output_hypernetworks_mlps.0.proj_in.bias, mask_decoder.output_hypernetworks_mlps.0.proj_out.weight, mask_decoder.output_hypernetworks_mlps.0.proj_out.bias, mask_decoder.output_hypernetworks_mlps.0.layers.0.weight, mask_decoder.output_hypernetworks_mlps.0.layers.0.bias, mask_decoder.output_hypernetworks_mlps.1.proj_in.weight, mask_decoder.output_hypernetworks_mlps.1.proj_in.bias, mask_decoder.output_hypernetworks_mlps.1.proj_out.weight, mask_decoder.output_hypernetworks_mlps.1.proj_out.bias, mask_decoder.output_hypernetworks_mlps.1.layers.0.weight, mask_decoder.output_hypernetworks_mlps.1.layers.0.bias, mask_decoder.output_hypernetworks_mlps.2.proj_in.weight, mask_decoder.output_hypernetworks_mlps.2.proj_in.bias, mask_decoder.output_hypernetworks_mlps.2.proj_out.weight, mask_decoder.output_hypernetworks_mlps.2.proj_out.bias, mask_decoder.output_hypernetworks_mlps.2.layers.0.weight, mask_decoder.output_hypernetworks_mlps.2.layers.0.bias, mask_decoder.output_hypernetworks_mlps.3.proj_in.weight, mask_decoder.output_hypernetworks_mlps.3.proj_in.bias, mask_decoder.output_hypernetworks_mlps.3.proj_out.weight, mask_decoder.output_hypernetworks_mlps.3.proj_out.bias, mask_decoder.output_hypernetworks_mlps.3.layers.0.weight, mask_decoder.output_hypernetworks_mlps.3.layers.0.bias, mask_decoder.iou_prediction_head.proj_in.weight, mask_decoder.iou_prediction_head.proj_in.bias, mask_decoder.iou_prediction_head.proj_out.weight, mask_decoder.iou_prediction_head.proj_out.bias, mask_decoder.iou_prediction_head.layers.0.weight, mask_decoder.iou_prediction_head.layers.0.bias\n",
      "\n",
      "11/30 00:14:29 - mmengine - INFO - load model from: ./pretrain/sam-vit-huge/pytorch_model.bin\n",
      "11/30 00:14:29 - mmengine - INFO - Loads checkpoint by local backend from path: ./pretrain/sam-vit-huge/pytorch_model.bin\n",
      "11/30 00:14:30 - mmengine - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: shared_image_embedding.positional_embedding, vision_encoder.pos_embed, vision_encoder.patch_embed.projection.weight, vision_encoder.patch_embed.projection.bias, vision_encoder.layers.0.layer_norm1.weight, vision_encoder.layers.0.layer_norm1.bias, vision_encoder.layers.0.attn.rel_pos_h, vision_encoder.layers.0.attn.rel_pos_w, vision_encoder.layers.0.attn.qkv.weight, vision_encoder.layers.0.attn.qkv.bias, vision_encoder.layers.0.attn.proj.weight, vision_encoder.layers.0.attn.proj.bias, vision_encoder.layers.0.layer_norm2.weight, vision_encoder.layers.0.layer_norm2.bias, vision_encoder.layers.0.mlp.lin1.weight, vision_encoder.layers.0.mlp.lin1.bias, vision_encoder.layers.0.mlp.lin2.weight, vision_encoder.layers.0.mlp.lin2.bias, vision_encoder.layers.1.layer_norm1.weight, vision_encoder.layers.1.layer_norm1.bias, vision_encoder.layers.1.attn.rel_pos_h, vision_encoder.layers.1.attn.rel_pos_w, vision_encoder.layers.1.attn.qkv.weight, vision_encoder.layers.1.attn.qkv.bias, vision_encoder.layers.1.attn.proj.weight, vision_encoder.layers.1.attn.proj.bias, vision_encoder.layers.1.layer_norm2.weight, vision_encoder.layers.1.layer_norm2.bias, vision_encoder.layers.1.mlp.lin1.weight, vision_encoder.layers.1.mlp.lin1.bias, vision_encoder.layers.1.mlp.lin2.weight, vision_encoder.layers.1.mlp.lin2.bias, vision_encoder.layers.2.layer_norm1.weight, vision_encoder.layers.2.layer_norm1.bias, vision_encoder.layers.2.attn.rel_pos_h, vision_encoder.layers.2.attn.rel_pos_w, vision_encoder.layers.2.attn.qkv.weight, vision_encoder.layers.2.attn.qkv.bias, vision_encoder.layers.2.attn.proj.weight, vision_encoder.layers.2.attn.proj.bias, vision_encoder.layers.2.layer_norm2.weight, vision_encoder.layers.2.layer_norm2.bias, vision_encoder.layers.2.mlp.lin1.weight, vision_encoder.layers.2.mlp.lin1.bias, vision_encoder.layers.2.mlp.lin2.weight, vision_encoder.layers.2.mlp.lin2.bias, vision_encoder.layers.3.layer_norm1.weight, vision_encoder.layers.3.layer_norm1.bias, vision_encoder.layers.3.attn.rel_pos_h, vision_encoder.layers.3.attn.rel_pos_w, vision_encoder.layers.3.attn.qkv.weight, vision_encoder.layers.3.attn.qkv.bias, vision_encoder.layers.3.attn.proj.weight, vision_encoder.layers.3.attn.proj.bias, vision_encoder.layers.3.layer_norm2.weight, vision_encoder.layers.3.layer_norm2.bias, vision_encoder.layers.3.mlp.lin1.weight, vision_encoder.layers.3.mlp.lin1.bias, vision_encoder.layers.3.mlp.lin2.weight, vision_encoder.layers.3.mlp.lin2.bias, vision_encoder.layers.4.layer_norm1.weight, vision_encoder.layers.4.layer_norm1.bias, vision_encoder.layers.4.attn.rel_pos_h, vision_encoder.layers.4.attn.rel_pos_w, vision_encoder.layers.4.attn.qkv.weight, vision_encoder.layers.4.attn.qkv.bias, vision_encoder.layers.4.attn.proj.weight, vision_encoder.layers.4.attn.proj.bias, vision_encoder.layers.4.layer_norm2.weight, vision_encoder.layers.4.layer_norm2.bias, vision_encoder.layers.4.mlp.lin1.weight, vision_encoder.layers.4.mlp.lin1.bias, vision_encoder.layers.4.mlp.lin2.weight, vision_encoder.layers.4.mlp.lin2.bias, vision_encoder.layers.5.layer_norm1.weight, vision_encoder.layers.5.layer_norm1.bias, vision_encoder.layers.5.attn.rel_pos_h, vision_encoder.layers.5.attn.rel_pos_w, vision_encoder.layers.5.attn.qkv.weight, vision_encoder.layers.5.attn.qkv.bias, vision_encoder.layers.5.attn.proj.weight, vision_encoder.layers.5.attn.proj.bias, vision_encoder.layers.5.layer_norm2.weight, vision_encoder.layers.5.layer_norm2.bias, vision_encoder.layers.5.mlp.lin1.weight, vision_encoder.layers.5.mlp.lin1.bias, vision_encoder.layers.5.mlp.lin2.weight, vision_encoder.layers.5.mlp.lin2.bias, vision_encoder.layers.6.layer_norm1.weight, vision_encoder.layers.6.layer_norm1.bias, vision_encoder.layers.6.attn.rel_pos_h, vision_encoder.layers.6.attn.rel_pos_w, vision_encoder.layers.6.attn.qkv.weight, vision_encoder.layers.6.attn.qkv.bias, vision_encoder.layers.6.attn.proj.weight, vision_encoder.layers.6.attn.proj.bias, vision_encoder.layers.6.layer_norm2.weight, vision_encoder.layers.6.layer_norm2.bias, vision_encoder.layers.6.mlp.lin1.weight, vision_encoder.layers.6.mlp.lin1.bias, vision_encoder.layers.6.mlp.lin2.weight, vision_encoder.layers.6.mlp.lin2.bias, vision_encoder.layers.7.layer_norm1.weight, vision_encoder.layers.7.layer_norm1.bias, vision_encoder.layers.7.attn.rel_pos_h, vision_encoder.layers.7.attn.rel_pos_w, vision_encoder.layers.7.attn.qkv.weight, vision_encoder.layers.7.attn.qkv.bias, vision_encoder.layers.7.attn.proj.weight, vision_encoder.layers.7.attn.proj.bias, vision_encoder.layers.7.layer_norm2.weight, vision_encoder.layers.7.layer_norm2.bias, vision_encoder.layers.7.mlp.lin1.weight, vision_encoder.layers.7.mlp.lin1.bias, vision_encoder.layers.7.mlp.lin2.weight, vision_encoder.layers.7.mlp.lin2.bias, vision_encoder.layers.8.layer_norm1.weight, vision_encoder.layers.8.layer_norm1.bias, vision_encoder.layers.8.attn.rel_pos_h, vision_encoder.layers.8.attn.rel_pos_w, vision_encoder.layers.8.attn.qkv.weight, vision_encoder.layers.8.attn.qkv.bias, vision_encoder.layers.8.attn.proj.weight, vision_encoder.layers.8.attn.proj.bias, vision_encoder.layers.8.layer_norm2.weight, vision_encoder.layers.8.layer_norm2.bias, vision_encoder.layers.8.mlp.lin1.weight, vision_encoder.layers.8.mlp.lin1.bias, vision_encoder.layers.8.mlp.lin2.weight, vision_encoder.layers.8.mlp.lin2.bias, vision_encoder.layers.9.layer_norm1.weight, vision_encoder.layers.9.layer_norm1.bias, vision_encoder.layers.9.attn.rel_pos_h, vision_encoder.layers.9.attn.rel_pos_w, vision_encoder.layers.9.attn.qkv.weight, vision_encoder.layers.9.attn.qkv.bias, vision_encoder.layers.9.attn.proj.weight, vision_encoder.layers.9.attn.proj.bias, vision_encoder.layers.9.layer_norm2.weight, vision_encoder.layers.9.layer_norm2.bias, vision_encoder.layers.9.mlp.lin1.weight, vision_encoder.layers.9.mlp.lin1.bias, vision_encoder.layers.9.mlp.lin2.weight, vision_encoder.layers.9.mlp.lin2.bias, vision_encoder.layers.10.layer_norm1.weight, vision_encoder.layers.10.layer_norm1.bias, vision_encoder.layers.10.attn.rel_pos_h, vision_encoder.layers.10.attn.rel_pos_w, vision_encoder.layers.10.attn.qkv.weight, vision_encoder.layers.10.attn.qkv.bias, vision_encoder.layers.10.attn.proj.weight, vision_encoder.layers.10.attn.proj.bias, vision_encoder.layers.10.layer_norm2.weight, vision_encoder.layers.10.layer_norm2.bias, vision_encoder.layers.10.mlp.lin1.weight, vision_encoder.layers.10.mlp.lin1.bias, vision_encoder.layers.10.mlp.lin2.weight, vision_encoder.layers.10.mlp.lin2.bias, vision_encoder.layers.11.layer_norm1.weight, vision_encoder.layers.11.layer_norm1.bias, vision_encoder.layers.11.attn.rel_pos_h, vision_encoder.layers.11.attn.rel_pos_w, vision_encoder.layers.11.attn.qkv.weight, vision_encoder.layers.11.attn.qkv.bias, vision_encoder.layers.11.attn.proj.weight, vision_encoder.layers.11.attn.proj.bias, vision_encoder.layers.11.layer_norm2.weight, vision_encoder.layers.11.layer_norm2.bias, vision_encoder.layers.11.mlp.lin1.weight, vision_encoder.layers.11.mlp.lin1.bias, vision_encoder.layers.11.mlp.lin2.weight, vision_encoder.layers.11.mlp.lin2.bias, vision_encoder.layers.12.layer_norm1.weight, vision_encoder.layers.12.layer_norm1.bias, vision_encoder.layers.12.attn.rel_pos_h, vision_encoder.layers.12.attn.rel_pos_w, vision_encoder.layers.12.attn.qkv.weight, vision_encoder.layers.12.attn.qkv.bias, vision_encoder.layers.12.attn.proj.weight, vision_encoder.layers.12.attn.proj.bias, vision_encoder.layers.12.layer_norm2.weight, vision_encoder.layers.12.layer_norm2.bias, vision_encoder.layers.12.mlp.lin1.weight, vision_encoder.layers.12.mlp.lin1.bias, vision_encoder.layers.12.mlp.lin2.weight, vision_encoder.layers.12.mlp.lin2.bias, vision_encoder.layers.13.layer_norm1.weight, vision_encoder.layers.13.layer_norm1.bias, vision_encoder.layers.13.attn.rel_pos_h, vision_encoder.layers.13.attn.rel_pos_w, vision_encoder.layers.13.attn.qkv.weight, vision_encoder.layers.13.attn.qkv.bias, vision_encoder.layers.13.attn.proj.weight, vision_encoder.layers.13.attn.proj.bias, vision_encoder.layers.13.layer_norm2.weight, vision_encoder.layers.13.layer_norm2.bias, vision_encoder.layers.13.mlp.lin1.weight, vision_encoder.layers.13.mlp.lin1.bias, vision_encoder.layers.13.mlp.lin2.weight, vision_encoder.layers.13.mlp.lin2.bias, vision_encoder.layers.14.layer_norm1.weight, vision_encoder.layers.14.layer_norm1.bias, vision_encoder.layers.14.attn.rel_pos_h, vision_encoder.layers.14.attn.rel_pos_w, vision_encoder.layers.14.attn.qkv.weight, vision_encoder.layers.14.attn.qkv.bias, vision_encoder.layers.14.attn.proj.weight, vision_encoder.layers.14.attn.proj.bias, vision_encoder.layers.14.layer_norm2.weight, vision_encoder.layers.14.layer_norm2.bias, vision_encoder.layers.14.mlp.lin1.weight, vision_encoder.layers.14.mlp.lin1.bias, vision_encoder.layers.14.mlp.lin2.weight, vision_encoder.layers.14.mlp.lin2.bias, vision_encoder.layers.15.layer_norm1.weight, vision_encoder.layers.15.layer_norm1.bias, vision_encoder.layers.15.attn.rel_pos_h, vision_encoder.layers.15.attn.rel_pos_w, vision_encoder.layers.15.attn.qkv.weight, vision_encoder.layers.15.attn.qkv.bias, vision_encoder.layers.15.attn.proj.weight, vision_encoder.layers.15.attn.proj.bias, vision_encoder.layers.15.layer_norm2.weight, vision_encoder.layers.15.layer_norm2.bias, vision_encoder.layers.15.mlp.lin1.weight, vision_encoder.layers.15.mlp.lin1.bias, vision_encoder.layers.15.mlp.lin2.weight, vision_encoder.layers.15.mlp.lin2.bias, vision_encoder.layers.16.layer_norm1.weight, vision_encoder.layers.16.layer_norm1.bias, vision_encoder.layers.16.attn.rel_pos_h, vision_encoder.layers.16.attn.rel_pos_w, vision_encoder.layers.16.attn.qkv.weight, vision_encoder.layers.16.attn.qkv.bias, vision_encoder.layers.16.attn.proj.weight, vision_encoder.layers.16.attn.proj.bias, vision_encoder.layers.16.layer_norm2.weight, vision_encoder.layers.16.layer_norm2.bias, vision_encoder.layers.16.mlp.lin1.weight, vision_encoder.layers.16.mlp.lin1.bias, vision_encoder.layers.16.mlp.lin2.weight, vision_encoder.layers.16.mlp.lin2.bias, vision_encoder.layers.17.layer_norm1.weight, vision_encoder.layers.17.layer_norm1.bias, vision_encoder.layers.17.attn.rel_pos_h, vision_encoder.layers.17.attn.rel_pos_w, vision_encoder.layers.17.attn.qkv.weight, vision_encoder.layers.17.attn.qkv.bias, vision_encoder.layers.17.attn.proj.weight, vision_encoder.layers.17.attn.proj.bias, vision_encoder.layers.17.layer_norm2.weight, vision_encoder.layers.17.layer_norm2.bias, vision_encoder.layers.17.mlp.lin1.weight, vision_encoder.layers.17.mlp.lin1.bias, vision_encoder.layers.17.mlp.lin2.weight, vision_encoder.layers.17.mlp.lin2.bias, vision_encoder.layers.18.layer_norm1.weight, vision_encoder.layers.18.layer_norm1.bias, vision_encoder.layers.18.attn.rel_pos_h, vision_encoder.layers.18.attn.rel_pos_w, vision_encoder.layers.18.attn.qkv.weight, vision_encoder.layers.18.attn.qkv.bias, vision_encoder.layers.18.attn.proj.weight, vision_encoder.layers.18.attn.proj.bias, vision_encoder.layers.18.layer_norm2.weight, vision_encoder.layers.18.layer_norm2.bias, vision_encoder.layers.18.mlp.lin1.weight, vision_encoder.layers.18.mlp.lin1.bias, vision_encoder.layers.18.mlp.lin2.weight, vision_encoder.layers.18.mlp.lin2.bias, vision_encoder.layers.19.layer_norm1.weight, vision_encoder.layers.19.layer_norm1.bias, vision_encoder.layers.19.attn.rel_pos_h, vision_encoder.layers.19.attn.rel_pos_w, vision_encoder.layers.19.attn.qkv.weight, vision_encoder.layers.19.attn.qkv.bias, vision_encoder.layers.19.attn.proj.weight, vision_encoder.layers.19.attn.proj.bias, vision_encoder.layers.19.layer_norm2.weight, vision_encoder.layers.19.layer_norm2.bias, vision_encoder.layers.19.mlp.lin1.weight, vision_encoder.layers.19.mlp.lin1.bias, vision_encoder.layers.19.mlp.lin2.weight, vision_encoder.layers.19.mlp.lin2.bias, vision_encoder.layers.20.layer_norm1.weight, vision_encoder.layers.20.layer_norm1.bias, vision_encoder.layers.20.attn.rel_pos_h, vision_encoder.layers.20.attn.rel_pos_w, vision_encoder.layers.20.attn.qkv.weight, vision_encoder.layers.20.attn.qkv.bias, vision_encoder.layers.20.attn.proj.weight, vision_encoder.layers.20.attn.proj.bias, vision_encoder.layers.20.layer_norm2.weight, vision_encoder.layers.20.layer_norm2.bias, vision_encoder.layers.20.mlp.lin1.weight, vision_encoder.layers.20.mlp.lin1.bias, vision_encoder.layers.20.mlp.lin2.weight, vision_encoder.layers.20.mlp.lin2.bias, vision_encoder.layers.21.layer_norm1.weight, vision_encoder.layers.21.layer_norm1.bias, vision_encoder.layers.21.attn.rel_pos_h, vision_encoder.layers.21.attn.rel_pos_w, vision_encoder.layers.21.attn.qkv.weight, vision_encoder.layers.21.attn.qkv.bias, vision_encoder.layers.21.attn.proj.weight, vision_encoder.layers.21.attn.proj.bias, vision_encoder.layers.21.layer_norm2.weight, vision_encoder.layers.21.layer_norm2.bias, vision_encoder.layers.21.mlp.lin1.weight, vision_encoder.layers.21.mlp.lin1.bias, vision_encoder.layers.21.mlp.lin2.weight, vision_encoder.layers.21.mlp.lin2.bias, vision_encoder.layers.22.layer_norm1.weight, vision_encoder.layers.22.layer_norm1.bias, vision_encoder.layers.22.attn.rel_pos_h, vision_encoder.layers.22.attn.rel_pos_w, vision_encoder.layers.22.attn.qkv.weight, vision_encoder.layers.22.attn.qkv.bias, vision_encoder.layers.22.attn.proj.weight, vision_encoder.layers.22.attn.proj.bias, vision_encoder.layers.22.layer_norm2.weight, vision_encoder.layers.22.layer_norm2.bias, vision_encoder.layers.22.mlp.lin1.weight, vision_encoder.layers.22.mlp.lin1.bias, vision_encoder.layers.22.mlp.lin2.weight, vision_encoder.layers.22.mlp.lin2.bias, vision_encoder.layers.23.layer_norm1.weight, vision_encoder.layers.23.layer_norm1.bias, vision_encoder.layers.23.attn.rel_pos_h, vision_encoder.layers.23.attn.rel_pos_w, vision_encoder.layers.23.attn.qkv.weight, vision_encoder.layers.23.attn.qkv.bias, vision_encoder.layers.23.attn.proj.weight, vision_encoder.layers.23.attn.proj.bias, vision_encoder.layers.23.layer_norm2.weight, vision_encoder.layers.23.layer_norm2.bias, vision_encoder.layers.23.mlp.lin1.weight, vision_encoder.layers.23.mlp.lin1.bias, vision_encoder.layers.23.mlp.lin2.weight, vision_encoder.layers.23.mlp.lin2.bias, vision_encoder.layers.24.layer_norm1.weight, vision_encoder.layers.24.layer_norm1.bias, vision_encoder.layers.24.attn.rel_pos_h, vision_encoder.layers.24.attn.rel_pos_w, vision_encoder.layers.24.attn.qkv.weight, vision_encoder.layers.24.attn.qkv.bias, vision_encoder.layers.24.attn.proj.weight, vision_encoder.layers.24.attn.proj.bias, vision_encoder.layers.24.layer_norm2.weight, vision_encoder.layers.24.layer_norm2.bias, vision_encoder.layers.24.mlp.lin1.weight, vision_encoder.layers.24.mlp.lin1.bias, vision_encoder.layers.24.mlp.lin2.weight, vision_encoder.layers.24.mlp.lin2.bias, vision_encoder.layers.25.layer_norm1.weight, vision_encoder.layers.25.layer_norm1.bias, vision_encoder.layers.25.attn.rel_pos_h, vision_encoder.layers.25.attn.rel_pos_w, vision_encoder.layers.25.attn.qkv.weight, vision_encoder.layers.25.attn.qkv.bias, vision_encoder.layers.25.attn.proj.weight, vision_encoder.layers.25.attn.proj.bias, vision_encoder.layers.25.layer_norm2.weight, vision_encoder.layers.25.layer_norm2.bias, vision_encoder.layers.25.mlp.lin1.weight, vision_encoder.layers.25.mlp.lin1.bias, vision_encoder.layers.25.mlp.lin2.weight, vision_encoder.layers.25.mlp.lin2.bias, vision_encoder.layers.26.layer_norm1.weight, vision_encoder.layers.26.layer_norm1.bias, vision_encoder.layers.26.attn.rel_pos_h, vision_encoder.layers.26.attn.rel_pos_w, vision_encoder.layers.26.attn.qkv.weight, vision_encoder.layers.26.attn.qkv.bias, vision_encoder.layers.26.attn.proj.weight, vision_encoder.layers.26.attn.proj.bias, vision_encoder.layers.26.layer_norm2.weight, vision_encoder.layers.26.layer_norm2.bias, vision_encoder.layers.26.mlp.lin1.weight, vision_encoder.layers.26.mlp.lin1.bias, vision_encoder.layers.26.mlp.lin2.weight, vision_encoder.layers.26.mlp.lin2.bias, vision_encoder.layers.27.layer_norm1.weight, vision_encoder.layers.27.layer_norm1.bias, vision_encoder.layers.27.attn.rel_pos_h, vision_encoder.layers.27.attn.rel_pos_w, vision_encoder.layers.27.attn.qkv.weight, vision_encoder.layers.27.attn.qkv.bias, vision_encoder.layers.27.attn.proj.weight, vision_encoder.layers.27.attn.proj.bias, vision_encoder.layers.27.layer_norm2.weight, vision_encoder.layers.27.layer_norm2.bias, vision_encoder.layers.27.mlp.lin1.weight, vision_encoder.layers.27.mlp.lin1.bias, vision_encoder.layers.27.mlp.lin2.weight, vision_encoder.layers.27.mlp.lin2.bias, vision_encoder.layers.28.layer_norm1.weight, vision_encoder.layers.28.layer_norm1.bias, vision_encoder.layers.28.attn.rel_pos_h, vision_encoder.layers.28.attn.rel_pos_w, vision_encoder.layers.28.attn.qkv.weight, vision_encoder.layers.28.attn.qkv.bias, vision_encoder.layers.28.attn.proj.weight, vision_encoder.layers.28.attn.proj.bias, vision_encoder.layers.28.layer_norm2.weight, vision_encoder.layers.28.layer_norm2.bias, vision_encoder.layers.28.mlp.lin1.weight, vision_encoder.layers.28.mlp.lin1.bias, vision_encoder.layers.28.mlp.lin2.weight, vision_encoder.layers.28.mlp.lin2.bias, vision_encoder.layers.29.layer_norm1.weight, vision_encoder.layers.29.layer_norm1.bias, vision_encoder.layers.29.attn.rel_pos_h, vision_encoder.layers.29.attn.rel_pos_w, vision_encoder.layers.29.attn.qkv.weight, vision_encoder.layers.29.attn.qkv.bias, vision_encoder.layers.29.attn.proj.weight, vision_encoder.layers.29.attn.proj.bias, vision_encoder.layers.29.layer_norm2.weight, vision_encoder.layers.29.layer_norm2.bias, vision_encoder.layers.29.mlp.lin1.weight, vision_encoder.layers.29.mlp.lin1.bias, vision_encoder.layers.29.mlp.lin2.weight, vision_encoder.layers.29.mlp.lin2.bias, vision_encoder.layers.30.layer_norm1.weight, vision_encoder.layers.30.layer_norm1.bias, vision_encoder.layers.30.attn.rel_pos_h, vision_encoder.layers.30.attn.rel_pos_w, vision_encoder.layers.30.attn.qkv.weight, vision_encoder.layers.30.attn.qkv.bias, vision_encoder.layers.30.attn.proj.weight, vision_encoder.layers.30.attn.proj.bias, vision_encoder.layers.30.layer_norm2.weight, vision_encoder.layers.30.layer_norm2.bias, vision_encoder.layers.30.mlp.lin1.weight, vision_encoder.layers.30.mlp.lin1.bias, vision_encoder.layers.30.mlp.lin2.weight, vision_encoder.layers.30.mlp.lin2.bias, vision_encoder.layers.31.layer_norm1.weight, vision_encoder.layers.31.layer_norm1.bias, vision_encoder.layers.31.attn.rel_pos_h, vision_encoder.layers.31.attn.rel_pos_w, vision_encoder.layers.31.attn.qkv.weight, vision_encoder.layers.31.attn.qkv.bias, vision_encoder.layers.31.attn.proj.weight, vision_encoder.layers.31.attn.proj.bias, vision_encoder.layers.31.layer_norm2.weight, vision_encoder.layers.31.layer_norm2.bias, vision_encoder.layers.31.mlp.lin1.weight, vision_encoder.layers.31.mlp.lin1.bias, vision_encoder.layers.31.mlp.lin2.weight, vision_encoder.layers.31.mlp.lin2.bias, vision_encoder.neck.conv1.weight, vision_encoder.neck.layer_norm1.weight, vision_encoder.neck.layer_norm1.bias, vision_encoder.neck.conv2.weight, vision_encoder.neck.layer_norm2.weight, vision_encoder.neck.layer_norm2.bias, mask_decoder.iou_token.weight, mask_decoder.mask_tokens.weight, mask_decoder.transformer.layers.0.self_attn.q_proj.weight, mask_decoder.transformer.layers.0.self_attn.q_proj.bias, mask_decoder.transformer.layers.0.self_attn.k_proj.weight, mask_decoder.transformer.layers.0.self_attn.k_proj.bias, mask_decoder.transformer.layers.0.self_attn.v_proj.weight, mask_decoder.transformer.layers.0.self_attn.v_proj.bias, mask_decoder.transformer.layers.0.self_attn.out_proj.weight, mask_decoder.transformer.layers.0.self_attn.out_proj.bias, mask_decoder.transformer.layers.0.layer_norm1.weight, mask_decoder.transformer.layers.0.layer_norm1.bias, mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.weight, mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.bias, mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.weight, mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.bias, mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.weight, mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.bias, mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.weight, mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.bias, mask_decoder.transformer.layers.0.layer_norm2.weight, mask_decoder.transformer.layers.0.layer_norm2.bias, mask_decoder.transformer.layers.0.mlp.lin1.weight, mask_decoder.transformer.layers.0.mlp.lin1.bias, mask_decoder.transformer.layers.0.mlp.lin2.weight, mask_decoder.transformer.layers.0.mlp.lin2.bias, mask_decoder.transformer.layers.0.layer_norm3.weight, mask_decoder.transformer.layers.0.layer_norm3.bias, mask_decoder.transformer.layers.0.layer_norm4.weight, mask_decoder.transformer.layers.0.layer_norm4.bias, mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.weight, mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.bias, mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.weight, mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.bias, mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.weight, mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.bias, mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.weight, mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.bias, mask_decoder.transformer.layers.1.self_attn.q_proj.weight, mask_decoder.transformer.layers.1.self_attn.q_proj.bias, mask_decoder.transformer.layers.1.self_attn.k_proj.weight, mask_decoder.transformer.layers.1.self_attn.k_proj.bias, mask_decoder.transformer.layers.1.self_attn.v_proj.weight, mask_decoder.transformer.layers.1.self_attn.v_proj.bias, mask_decoder.transformer.layers.1.self_attn.out_proj.weight, mask_decoder.transformer.layers.1.self_attn.out_proj.bias, mask_decoder.transformer.layers.1.layer_norm1.weight, mask_decoder.transformer.layers.1.layer_norm1.bias, mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.weight, mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.bias, mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.weight, mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.bias, mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.weight, mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.bias, mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.weight, mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.bias, mask_decoder.transformer.layers.1.layer_norm2.weight, mask_decoder.transformer.layers.1.layer_norm2.bias, mask_decoder.transformer.layers.1.mlp.lin1.weight, mask_decoder.transformer.layers.1.mlp.lin1.bias, mask_decoder.transformer.layers.1.mlp.lin2.weight, mask_decoder.transformer.layers.1.mlp.lin2.bias, mask_decoder.transformer.layers.1.layer_norm3.weight, mask_decoder.transformer.layers.1.layer_norm3.bias, mask_decoder.transformer.layers.1.layer_norm4.weight, mask_decoder.transformer.layers.1.layer_norm4.bias, mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.weight, mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.bias, mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.weight, mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.bias, mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.weight, mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.bias, mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.weight, mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.bias, mask_decoder.transformer.final_attn_token_to_image.q_proj.weight, mask_decoder.transformer.final_attn_token_to_image.q_proj.bias, mask_decoder.transformer.final_attn_token_to_image.k_proj.weight, mask_decoder.transformer.final_attn_token_to_image.k_proj.bias, mask_decoder.transformer.final_attn_token_to_image.v_proj.weight, mask_decoder.transformer.final_attn_token_to_image.v_proj.bias, mask_decoder.transformer.final_attn_token_to_image.out_proj.weight, mask_decoder.transformer.final_attn_token_to_image.out_proj.bias, mask_decoder.transformer.layer_norm_final_attn.weight, mask_decoder.transformer.layer_norm_final_attn.bias, mask_decoder.upscale_conv1.weight, mask_decoder.upscale_conv1.bias, mask_decoder.upscale_conv2.weight, mask_decoder.upscale_conv2.bias, mask_decoder.upscale_layer_norm.weight, mask_decoder.upscale_layer_norm.bias, mask_decoder.output_hypernetworks_mlps.0.proj_in.weight, mask_decoder.output_hypernetworks_mlps.0.proj_in.bias, mask_decoder.output_hypernetworks_mlps.0.proj_out.weight, mask_decoder.output_hypernetworks_mlps.0.proj_out.bias, mask_decoder.output_hypernetworks_mlps.0.layers.0.weight, mask_decoder.output_hypernetworks_mlps.0.layers.0.bias, mask_decoder.output_hypernetworks_mlps.1.proj_in.weight, mask_decoder.output_hypernetworks_mlps.1.proj_in.bias, mask_decoder.output_hypernetworks_mlps.1.proj_out.weight, mask_decoder.output_hypernetworks_mlps.1.proj_out.bias, mask_decoder.output_hypernetworks_mlps.1.layers.0.weight, mask_decoder.output_hypernetworks_mlps.1.layers.0.bias, mask_decoder.output_hypernetworks_mlps.2.proj_in.weight, mask_decoder.output_hypernetworks_mlps.2.proj_in.bias, mask_decoder.output_hypernetworks_mlps.2.proj_out.weight, mask_decoder.output_hypernetworks_mlps.2.proj_out.bias, mask_decoder.output_hypernetworks_mlps.2.layers.0.weight, mask_decoder.output_hypernetworks_mlps.2.layers.0.bias, mask_decoder.output_hypernetworks_mlps.3.proj_in.weight, mask_decoder.output_hypernetworks_mlps.3.proj_in.bias, mask_decoder.output_hypernetworks_mlps.3.proj_out.weight, mask_decoder.output_hypernetworks_mlps.3.proj_out.bias, mask_decoder.output_hypernetworks_mlps.3.layers.0.weight, mask_decoder.output_hypernetworks_mlps.3.layers.0.bias, mask_decoder.iou_prediction_head.proj_in.weight, mask_decoder.iou_prediction_head.proj_in.bias, mask_decoder.iou_prediction_head.proj_out.weight, mask_decoder.iou_prediction_head.proj_out.bias, mask_decoder.iou_prediction_head.layers.0.weight, mask_decoder.iou_prediction_head.layers.0.bias, prompt_encoder.shared_embedding.positional_embedding\n",
      "\n",
      "11/30 00:14:31 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "11/30 00:14:31 - mmengine - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.30s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.21s)\n",
      "creating index...\n",
      "index created!\n",
      "Loads checkpoint by local backend from path: pretrain/multi_class_model.pth\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "pretrain/multi_class_model.pth can not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22/3918475564.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Run testing - this will automatically evaluate with CocoMetric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mmengine/runner/runner.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1820\u001b[0m         \u001b[0;31m# make sure checkpoint-related hooks are triggered after `before_run`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1821\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_or_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1823\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mmengine/runner/runner.py\u001b[0m in \u001b[0;36mload_or_resume\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1697\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_loaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1698\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_from\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1699\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_from\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1700\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_loaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mmengine/runner/runner.py\u001b[0m in \u001b[0;36mload_checkpoint\u001b[0;34m(self, filename, map_location, strict, revise_keys)\u001b[0m\n\u001b[1;32m   2125\u001b[0m                 \u001b[0mthe\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m'module.'\u001b[0m \u001b[0mby\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'^module\\\\.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2126\u001b[0m         \"\"\"\n\u001b[0;32m-> 2127\u001b[0;31m         \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2129\u001b[0m         \u001b[0;31m# Add comments to describe the usage of `after_load_ckpt`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mmengine/runner/checkpoint.py\u001b[0m in \u001b[0;36m_load_checkpoint\u001b[0;34m(filename, map_location, logger)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0minformation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mdepends\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \"\"\"\n\u001b[0;32m--> 548\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointLoader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mmengine/runner/checkpoint.py\u001b[0m in \u001b[0;36mload_checkpoint\u001b[0;34m(cls, filename, map_location, logger)\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0;34mf'{filename}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             logger=logger)\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcheckpoint_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mmengine/runner/checkpoint.py\u001b[0m in \u001b[0;36mload_from_local\u001b[0;34m(filename, map_location)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{filename} can not be found.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: pretrain/multi_class_model.pth can not be found."
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/USIS10K\n",
    "\n",
    "from mmengine.runner import Runner\n",
    "from mmengine.config import Config\n",
    "\n",
    "# Load config\n",
    "cfg = Config.fromfile('project/our/configs/multiclass_usis_train.py')\n",
    "\n",
    "# Update checkpoint path\n",
    "cfg.load_from = 'pretrain/multi_class_model.pth'\n",
    "\n",
    "# Build runner\n",
    "runner = Runner.from_cfg(cfg)\n",
    "\n",
    "# Run testing - this will automatically evaluate with CocoMetric\n",
    "runner.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fd0973",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python tools/test.py \\\n",
    "    project/our/configs/multiclass_usis_train.py \\\n",
    "    checkpoints/multi_class_model.pth \\\n",
    "    --show-dir results_mc \\\n",
    "    --out results_mc.pkl"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8864826,
     "sourceId": 13912587,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8869834,
     "sourceId": 13919799,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 405.067857,
   "end_time": "2025-11-30T00:14:37.323839",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-30T00:07:52.255982",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
